---
layout: post
title: Roomac
categories:
  - Robots
excerpt: |
  The affordable general-purpose robot that I built from scratch. Using it I implemented fetching bottle application.
  <center><img width="600" src="/pics/16_roomac/roomac_manipulation_navigation.gif"></center>
---
{% include button.html text="Github repository" icon="github" link="https://github.com/macorobots/roomac_ros" color="#0366d6" %}

Roomac is a low-cost autonomous mobile manipulation robot that consists of a differential drive mobile base and a 5-DoF manipulator with a gripper. The costs of the whole construction summed up to around 550$ and using this platform I was able to create a proof-of-concept application - fetching a bottle to the user. This project was described in more detail in my [master's thesis](https://raw.githubusercontent.com/macstepien/macstepien.github.io/master/files/masters_thesis_maciej_stepien.pdf).


{% include video.html id="toHzFQhAP44" title="roomac autonomously fetching bottle demo" %}


Software is based on ROS Melodic, I used many ROS packages, some of them are RTABMap, move_base (with TEB as a local planner), robot_localization, MoveIt with BioIKKinematics (robot’s arm has 5DoF and only with BioIK I was able to achieve desired positions), ar_track_alvar.

Working with cheap components was quite a challenge and I’m still amazed that it was possible to configure TEB to smoothly control the drill motors that I used in the base. Overall I worked on this project alone, and it is awesome, what is possible to achieve using ROS, even without a large budget.

Most of the construction was 3D printed, the base consists of DC drill motors, encoders, IMU and STM32BluePill MCU. In the manipulator there are 6 servos: 3 XYZrobot A1-16 and 3 cheaper TowerPro (MG996R and 2xSG-92R) which are controlled by the second STM32BluePill. To detect obstacles and create a map of the environment I used Kinect (the one from Xbox360). The second Kinect is mounted above the table and it is used for the manipulation (robot’s position is detected using ARTags). Navigation computations are run on the laptop placed in the base of the robot.

If you’re interested in this project, you can check out the Github repository 38 and my master’s thesis 17, which describes it in much more detail.

Apart from construction I also created a simulation of the robot in the Gazebo. There is a docker image with it, so executing the demo is really easy (basically you only need to copy and paste two commands). For further details please refer to the instruction in the README on Github, hope you like it!
