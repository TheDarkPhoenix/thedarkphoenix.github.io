<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2022-10-20T21:18:08+02:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Maciej Stępień</title><subtitle>Projects</subtitle><entry><title type="html">Roomac</title><link href="http://localhost:4000/roboty/2022/10/20/roomac/" rel="alternate" type="text/html" title="Roomac" /><published>2022-10-20T00:00:00+02:00</published><updated>2022-10-20T00:00:00+02:00</updated><id>http://localhost:4000/roboty/2022/10/20/roomac</id><content type="html" xml:base="http://localhost:4000/roboty/2022/10/20/roomac/"><![CDATA[<p>Roomac is a low-cost autonomous mobile manipulation robot. It consists of differential drive mobile base and 5-DoF manipulator with gripper. Whole construction costed around 550$ and using this platform I was able to prepare proof-of-concept application - bringing bottle to the user.</p>

<div class="embed-container">
  <iframe width="720" height="405" src="https://drive.google.com/file/d/15o_CPwpEsHFUy_6dhViRdDjdI0ZCkai7/preview" frameborder="0" allowfullscreen="">
  </iframe>
</div>]]></content><author><name></name></author><category term="Roboty" /><summary type="html"><![CDATA[Affordable autonomous mobile manipulation robot]]></summary></entry><entry><title type="html">Human following robot</title><link href="http://localhost:4000/roboty/2019/09/24/human-following-robot/" rel="alternate" type="text/html" title="Human following robot" /><published>2019-09-24T00:00:00+02:00</published><updated>2019-09-24T00:00:00+02:00</updated><id>http://localhost:4000/roboty/2019/09/24/human-following-robot</id><content type="html" xml:base="http://localhost:4000/roboty/2019/09/24/human-following-robot/"><![CDATA[<p>In this tutorial I describe one way to make robot detect and follow people - it won’t make a great spy but could be useful to carry luggage or groceries. Whole system was implemented on Husarion’s ROSbot with ESP32 as a remote. To find people I used scans from LiDAR (RPLidar A2) with my detector, which is simple but turned out to be fast and quite reliable. I also checked other LiDAR approaches available on ROS - leg_detector and leg_tracker but in this case didn’t perform well enough. Another package I tested is upper_body_detector, which uses RGBD camera to detect humans. As name suggests it needs to see upper part of body - this will be a problem if we want our robot to stay close, also in this case it didn’t perform very well and was slower.</p>

<div class="embed-container">
  <iframe width="720" height="405" src="https://drive.google.com/file/d/1jNWkf1M97UBEypOCILnGTzXXnH618SYN/preview" frameborder="0" allowfullscreen="">
  </iframe>
</div>

<h2 id="setup">Setup</h2>

<h3 id="esp32-remote">ESP32 Remote</h3>

<h4 id="environment">Environment</h4>

<p>You will need to follow tutorial about <a href="https://www.hackster.io/khasreto/run-rosserial-over-the-internet-with-esp32-0615f5">setting up rosserial connection over Internet with ESP32</a>. On ROSbot prepare Husarnet connection and Rosserial for Husarnet. I recommend to set up Arduino IDE on your computer (remember to also get Rosserial for Husarnet).</p>

<h4 id="code">Code</h4>

<p>Create new sketch in Arduino IDE and copy code:<br />
<a href="https://github.com/macstepien/RosbotFollowerESPRemote/blob/master/rosbot_remote.ino">ESP Remote Code</a></p>

<p>Then get your Husarnet join code and customize code as described in <a href="https://www.hackster.io/khasreto/run-rosserial-over-the-internet-with-esp32-0615f5">ESP32 Husarnet Tutorial</a></p>

<h4 id="wiring">Wiring</h4>

<p>Wire your ESP32 accordingly to schematics:</p>

<figure class="figure  figure--center">
  <img class="image" src="/pics/RosbotFollower/remoteSchematics.png" alt="" width="600" height="800" />
  
</figure>

<p>As a source of power you can use a Powerbank connected to the ESP.</p>

<h3 id="rosbot">ROSbot</h3>

<p>This project is meant to run on CORE2 with Mbed firmware. So be sure that you updated your firmware as described in <a href="https://husarion.com/tutorials/howtostart/rosbot---quick-start/">ROSbot quick start</a>. On ROSbot you will need to install following dependencies:</p>

<ul>
  <li><strong>scikit-learn</strong> python library (for clusterization)
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>apt-get <span class="nb">install </span>python-scikits-learn
</code></pre></div>    </div>
  </li>
  <li>
    <p><strong>pykalman</strong><br />
Follow installation tutorial on <a href="https://pykalman.github.io/">pykalman page</a></p>
  </li>
  <li><strong>rosbot_description</strong> package (for URDF visualization model and bridge node)<br />
Go to your ROS workspace and clone repository:
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cd</span> ~/ros_workspace/src
git clone https://github.com/husarion/rosbot_description.git
</code></pre></div>    </div>
    <p>Install dependencies:</p>
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cd</span> ~/ros_workspace
rosdep <span class="nb">install</span> <span class="nt">--from-paths</span> src <span class="nt">--ignore-src</span> <span class="nt">-r</span> <span class="nt">-y</span>
</code></pre></div>    </div>
  </li>
  <li><strong>rosbot_ekf</strong><br />
Install dependency:
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>apt-get <span class="nb">install </span>ros-kinetic-robot-localization
</code></pre></div>    </div>
    <p>Get package:</p>
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git clone https://github.com/byq77/rosbot_ekf.git
</code></pre></div>    </div>
  </li>
</ul>

<p>Then go back to src folder in your workspace:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cd</span> ~/ros_workspace/src
</code></pre></div></div>

<p>Download code:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git clone https://github.com/macstepien/rosbot_follower.git
</code></pre></div></div>

<p>And finally build your workspace:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cd</span> ~/ros_workspace
catkin_make
</code></pre></div></div>

<h2 id="usage">Usage</h2>

<p>There are two options available:</p>

<ul>
  <li>followerSlow - better if you have little space and walk slowly.<br />
To run it you only need to copy this commande into new terminal window:
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>roslaunch rosbot_follower followerSlow.launch
</code></pre></div>    </div>
  </li>
  <li>followerKalman - this one should be able to follow you with normal walking, but it also needs some space to gain speed.<br />
Roslaunch command:
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>roslaunch rosbot_follower followerKalman.launch
</code></pre></div>    </div>
  </li>
</ul>

<p>After whole system is up and running stand in front of ROSbot, but not too far away. When you are detected blue LED on ESP should turn on. Then you can press first button (the one closer to ESP on schematics) and if you start walking robot should follow you. When LED turns off it means that algorithm lost detection of you and need to recalibrate (stand closer to robot and wait until blue LED is back on). If robot had false detection you can calibrate again by pressing second button. On RViz you can see visualization: scan from LiDAR, robot model and detections. Green spheres are all potential legs, blue cylinders are detected legs and red tall cylinder is human position. In version with Kalman filter we also publish circle around human, which shows how much estimated position differs from measurement.</p>

<figure class="figure  figure--center">
  <img class="image" src="/pics/RosbotFollower/rviz.png" alt="" width="600" height="800" />
  
</figure>

<h3 id="troubleshooting">Troubleshooting</h3>

<ul>
  <li><strong>LED doesn’t turn on</strong> - check RViz if you can see detected human (red cylinder). If there is a detection then press Dead Man’s Button and try to walk.</li>
  <li><strong>ROSbot doesn’t respond</strong> - you should check your connection to ESP32. You can do so by echoing button topic:
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>rostopic <span class="nb">echo</span> /esp_remote/start
</code></pre></div>    </div>
    <p>If nothing can be seen, try restarting your ESP by turning it off and on again.</p>
  </li>
</ul>

<h2 id="algorithm-walkthrough">Algorithm walkthrough</h2>

<p>First we will go through slower version, as it is simpler. Main part of this code is scan callback where all the magic happens - data from LiDAR is analyzed and people are detected. Whole process consists of 5 steps:</p>

<ol>
  <li>Clusterization</li>
  <li>Leg detection</li>
  <li>Human detection</li>
  <li>Marker publishing</li>
  <li>Control</li>
</ol>

<h3 id="1-clusterization">1. Clusterization</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">scanCallback</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scan</span><span class="p">):</span>
    <span class="n">clusterList</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">findClusters</span><span class="p">(</span><span class="n">scan</span><span class="p">)</span>
    <span class="p">...</span>
</code></pre></div></div>

<p>First we find clusters in our scan using Euclidean Clusterization Algorithm:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">findClusters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scan</span><span class="p">):</span>
    <span class="n">pointsList</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
    <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">scan</span><span class="p">.</span><span class="n">ranges</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">r</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="p">.</span><span class="n">minRange</span> <span class="ow">and</span> <span class="n">r</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="p">.</span><span class="n">maxRange</span><span class="p">:</span>
            <span class="n">alfa</span> <span class="o">=</span> <span class="n">scan</span><span class="p">.</span><span class="n">angle_min</span> <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="n">scan</span><span class="p">.</span><span class="n">angle_increment</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">r</span> <span class="o">*</span> <span class="n">math</span><span class="p">.</span><span class="n">cos</span><span class="p">(</span><span class="n">alfa</span><span class="p">)</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">r</span> <span class="o">*</span> <span class="n">math</span><span class="p">.</span><span class="n">sin</span><span class="p">(</span><span class="n">alfa</span><span class="p">)</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">alfa</span> <span class="o">&gt;</span> <span class="o">-</span><span class="n">math</span><span class="p">.</span><span class="n">pi</span> <span class="ow">and</span> <span class="n">alfa</span> <span class="o">&lt;</span> <span class="o">-</span><span class="bp">self</span><span class="p">.</span><span class="n">maxAngle</span><span class="p">)</span> <span class="ow">or</span> \
                <span class="p">(</span><span class="n">alfa</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="p">.</span><span class="n">maxAngle</span> <span class="ow">and</span> <span class="n">alfa</span> <span class="o">&lt;</span> <span class="n">math</span><span class="p">.</span><span class="n">pi</span><span class="p">):</span>
                <span class="n">pointsList</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">pointsList</span><span class="p">,</span> <span class="p">[[</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">]],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">r</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="p">.</span><span class="n">minRange</span><span class="p">:</span>
            <span class="n">rospy</span><span class="p">.</span><span class="n">logerr</span><span class="p">(</span><span class="s">"Obstacle detected"</span><span class="p">)</span>
            <span class="k">return</span> <span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))]</span>
        <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">db</span> <span class="o">=</span> <span class="n">DBSCAN</span><span class="p">(</span><span class="n">eps</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">clusterizationMaxDistanceParam</span><span class="p">,</span>
                <span class="n">min_samples</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">clusterizationMinSamplesParam</span><span class="p">).</span><span class="n">fit</span><span class="p">(</span><span class="n">pointsList</span><span class="p">)</span>
    <span class="n">core_samples_mask</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">db</span><span class="p">.</span><span class="n">labels_</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
    <span class="n">core_samples_mask</span><span class="p">[</span><span class="n">db</span><span class="p">.</span><span class="n">core_sample_indices_</span><span class="p">]</span> <span class="o">=</span> <span class="bp">True</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">db</span><span class="p">.</span><span class="n">labels_</span>
    <span class="n">n_clusters_</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">labels</span><span class="p">))</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span> <span class="k">if</span> <span class="o">-</span><span class="mi">1</span> <span class="ow">in</span> <span class="n">labels</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">unique_labels</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
    <span class="n">clusterList</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">unique_labels</span><span class="p">:</span>
        <span class="n">class_member_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">labels</span> <span class="o">==</span> <span class="n">k</span><span class="p">)</span>
        <span class="n">xy</span> <span class="o">=</span> <span class="n">pointsList</span><span class="p">[</span><span class="n">class_member_mask</span> <span class="o">&amp;</span> <span class="n">core_samples_mask</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">xy</span><span class="p">.</span><span class="nb">any</span><span class="p">():</span>
            <span class="n">clusterList</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">xy</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">clusterList</span>
</code></pre></div></div>

<p>Here we have few parameters that you can customize:</p>

<ul>
  <li><strong>minRange</strong> - used to filter ranges from lidar points, if anything gets closer than that, then ROSbot treats it as obstacle and stops</li>
  <li><strong>maxRange</strong> - data from lidar further than that value are dismissed</li>
  <li><strong>maxAngle</strong> - readings have to be in front of ROSbot in ranges (maxAngle, Pi) u (-Pi, -maxAngle)</li>
  <li><strong>clusterizationMaxDistanceParam</strong> - maximum distance between points to add new point to cluster</li>
  <li><strong>clusterizationMinSamplesParam</strong> - minimum number of points in cluster</li>
</ul>

<p>More information about <a href="https://scikit-learn.org/stable/modules/clustering.html#dbscan">DBSCAN clusterization</a></p>

<p>Back to scanCallback:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">scanCallback</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scan</span><span class="p">):</span>
    <span class="p">...</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">clusterList</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    	<span class="n">rospy</span><span class="p">.</span><span class="n">logwarn</span><span class="p">(</span><span class="s">"No clusters detected"</span><span class="p">)</span>
    	<span class="k">if</span> <span class="n">rospy</span><span class="p">.</span><span class="n">get_time</span><span class="p">()</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">lastDetectionTime</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="p">.</span><span class="n">detectionTimeout</span><span class="p">:</span>
            <span class="n">humanPosition</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">lastHumanPosition</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">controlRosbot</span><span class="p">(</span><span class="n">humanPosition</span><span class="p">)</span>
    	<span class="k">else</span><span class="p">:</span>
            <span class="n">led</span> <span class="o">=</span> <span class="n">Bool</span><span class="p">()</span>
            <span class="n">led</span><span class="p">.</span><span class="n">data</span> <span class="o">=</span> <span class="bp">False</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">ledPub</span><span class="p">.</span><span class="n">publish</span><span class="p">(</span><span class="n">led</span><span class="p">)</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">positionCalibration</span> <span class="o">=</span> <span class="bp">True</span>
            <span class="n">rosbotControl</span> <span class="o">=</span> <span class="n">Twist</span><span class="p">()</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">speedPub</span><span class="p">.</span><span class="n">publish</span><span class="p">(</span><span class="n">rosbotControl</span><span class="p">)</span>
    	<span class="k">return</span>
    <span class="k">elif</span> <span class="p">(</span><span class="n">clusterList</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">clusterList</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
    	<span class="n">led</span> <span class="o">=</span> <span class="n">Bool</span><span class="p">()</span>
    	<span class="n">led</span><span class="p">.</span><span class="n">data</span> <span class="o">=</span> <span class="bp">False</span>
    	<span class="bp">self</span><span class="p">.</span><span class="n">ledPub</span><span class="p">.</span><span class="n">publish</span><span class="p">(</span><span class="n">led</span><span class="p">)</span>
    	<span class="bp">self</span><span class="p">.</span><span class="n">positionCalibration</span> <span class="o">=</span> <span class="bp">True</span>
    	<span class="n">rosbotControl</span> <span class="o">=</span> <span class="n">Twist</span><span class="p">()</span>
    	<span class="bp">self</span><span class="p">.</span><span class="n">speedPub</span><span class="p">.</span><span class="n">publish</span><span class="p">(</span><span class="n">rosbotControl</span><span class="p">)</span>
    	<span class="k">return</span>
    <span class="p">...</span>
</code></pre></div></div>

<p>In here we check results of clusterization. If we didn’t detect anything, we continue movement in last seen human position. That is until our last seen position is too old - then we need to stop and assume we lost track of our human, which we signal through LED.<br />
We pass special value when obstacle is detected - in first cluster first point is set to (0,0). In this case robot needs to stop immediately, as obstacle is too close.</p>

<ul>
  <li><strong>detectionTimeout</strong> - how much time (in seconds) we can trust last seen position and follow it</li>
</ul>

<h3 id="2-leg-detection">2. Leg detection</h3>

<p>Next step is leg detection:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">scanCallback</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scan</span><span class="p">):</span>
    <span class="p">...</span>
    <span class="n">sortedClusters</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">detectLegs</span><span class="p">(</span><span class="n">clusterList</span><span class="p">)</span>
    <span class="p">...</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">detectLegs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">clusterList</span><span class="p">):</span>
    <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">sortedClusters</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">cluster</span> <span class="ow">in</span> <span class="n">clusterList</span><span class="p">:</span>
    	<span class="n">xMax</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="n">cluster</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span>
    	<span class="n">xMin</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">min</span><span class="p">(</span><span class="n">cluster</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span>
    	<span class="n">yMax</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="n">cluster</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
    	<span class="n">yMin</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">min</span><span class="p">(</span><span class="n">cluster</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
    	<span class="n">xDistance</span> <span class="o">=</span> <span class="n">xMax</span> <span class="o">-</span> <span class="n">xMin</span>
    	<span class="n">yDistance</span> <span class="o">=</span> <span class="n">yMax</span> <span class="o">-</span> <span class="n">yMin</span>
    	<span class="n">proportion</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">xDistance</span><span class="p">,</span><span class="n">yDistance</span><span class="p">)</span><span class="o">/</span><span class="nb">min</span><span class="p">(</span><span class="n">xDistance</span><span class="p">,</span> <span class="n">yDistance</span><span class="p">)</span>
    	<span class="n">area</span> <span class="o">=</span> <span class="n">xDistance</span><span class="o">*</span><span class="n">yDistance</span>
    	<span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">xDistance</span><span class="p">,</span><span class="n">yDistance</span><span class="p">)</span><span class="o">-</span><span class="bp">self</span><span class="p">.</span><span class="n">legWidth</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="p">.</span><span class="n">dLegWidth</span><span class="p">:</span>
    		<span class="k">continue</span>
    	<span class="n">xMean</span> <span class="o">=</span> <span class="p">(</span><span class="n">xMax</span><span class="o">+</span><span class="n">xMin</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span>
    	<span class="n">yMean</span> <span class="o">=</span> <span class="p">(</span><span class="n">yMax</span><span class="o">+</span><span class="n">yMin</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span>
    	<span class="n">cone</span> <span class="o">=</span> <span class="n">Point</span><span class="p">()</span>
    	<span class="n">cone</span><span class="p">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">xMean</span>
    	<span class="n">cone</span><span class="p">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">yMean</span>
    	<span class="n">cone</span><span class="p">.</span><span class="n">z</span> <span class="o">=</span> <span class="mi">0</span>
    	<span class="n">sortedClusters</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">cone</span><span class="p">)</span>
    <span class="n">sortedClusters</span><span class="p">.</span><span class="n">sort</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">math</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">x</span><span class="p">.</span><span class="n">y</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">sortedClusters</span>
</code></pre></div></div>

<p>In this section we go through each cluster and calculate its bounding rectangle. Then we filter our data with following rule: longer side of rectangle can have maximal length of legWidth + dLegWidth (meaning that we assume leg width of legWidth with upper toleration dLegWidth). I encourage you to experiment with it and maybe try other conditions e.g. area and sides proportions. If cluster passes we find its centroid and save it for further calculations. As last thing we sort our potential legs by distance from ROSbot.</p>

<ul>
  <li><strong>legWidth</strong> - width of the leg</li>
  <li><strong>dLegWidth</strong> - toleration of leg width</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">scanCallback</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scan</span><span class="p">):</span>
    <span class="p">...</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">sortedClusters</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    	<span class="n">rospy</span><span class="p">.</span><span class="n">logwarn</span><span class="p">(</span><span class="s">"No legs detected"</span><span class="p">)</span>
    	<span class="k">if</span> <span class="n">rospy</span><span class="p">.</span><span class="n">get_time</span><span class="p">()</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">lastDetectionTime</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="p">.</span><span class="n">detectionTimeout</span><span class="p">:</span>
            <span class="n">humanPosition</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">lastHumanPosition</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">controlRosbot</span><span class="p">(</span><span class="n">humanPosition</span><span class="p">)</span>
    	<span class="k">else</span><span class="p">:</span>
            <span class="n">led</span> <span class="o">=</span> <span class="n">Bool</span><span class="p">()</span>
            <span class="n">led</span><span class="p">.</span><span class="n">data</span> <span class="o">=</span> <span class="bp">False</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">ledPub</span><span class="p">.</span><span class="n">publish</span><span class="p">(</span><span class="n">led</span><span class="p">)</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">positionCalibration</span> <span class="o">=</span> <span class="bp">True</span>
            <span class="n">rosbotControl</span> <span class="o">=</span> <span class="n">Twist</span><span class="p">()</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">speedPub</span><span class="p">.</span><span class="n">publish</span><span class="p">(</span><span class="n">rosbotControl</span><span class="p">)</span>
    	<span class="k">return</span>
    <span class="p">...</span>
</code></pre></div></div>

<p>Similar to previous step we check results of leg detection. No legs found - we allow ROSbot to move for some time. This step is necessary to smooth out movement - sometimes in only one frame we don’t detect any legs, which can cause robot to stop and go.</p>

<h3 id="3-human-detection">3. Human detection</h3>

<p>We estimate human position through analysis of legs detections:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">scanCallback</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scan</span><span class="p">):</span>
    <span class="p">...</span>
    <span class="p">(</span><span class="n">firstLeg</span><span class="p">,</span> <span class="n">secondLeg</span><span class="p">,</span> <span class="n">humanPosition</span><span class="p">,</span> <span class="n">firstLegDetected</span><span class="p">,</span> <span class="n">twoLegsDetected</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">detectHuman</span><span class="p">(</span><span class="n">sortedClusters</span><span class="p">)</span>
    <span class="p">...</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">detectHuman</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sortedClusters</span><span class="p">):</span>
    <span class="n">firstLeg</span> <span class="o">=</span> <span class="n">sortedClusters</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">firstLegDetected</span> <span class="o">=</span> <span class="bp">False</span>
    <span class="n">twoLegsDetected</span> <span class="o">=</span> <span class="bp">False</span>
    <span class="n">secondLeg</span> <span class="o">=</span> <span class="n">Point</span><span class="p">()</span>
    <span class="n">humanPosition</span> <span class="o">=</span> <span class="n">Point</span><span class="p">()</span>
    <span class="n">humanPositionTemp</span> <span class="o">=</span> <span class="n">Point</span><span class="p">()</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">sortedClusters</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
    	<span class="n">sortedClusters</span><span class="p">.</span><span class="n">sort</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">math</span><span class="p">.</span><span class="n">sqrt</span><span class="p">((</span><span class="n">x</span><span class="p">.</span><span class="n">x</span><span class="o">-</span><span class="n">firstLeg</span><span class="p">.</span><span class="n">x</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">y</span><span class="o">-</span><span class="n">firstLeg</span><span class="p">.</span><span class="n">y</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>
    	<span class="n">secondLeg</span> <span class="o">=</span> <span class="n">sortedClusters</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    	<span class="n">legDistance</span> <span class="o">=</span> <span class="n">math</span><span class="p">.</span><span class="n">sqrt</span><span class="p">((</span><span class="n">firstLeg</span><span class="p">.</span><span class="n">x</span> <span class="o">-</span> <span class="n">secondLeg</span><span class="p">.</span><span class="n">x</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="p">(</span><span class="n">firstLeg</span><span class="p">.</span><span class="n">y</span> <span class="o">-</span> <span class="n">secondLeg</span><span class="p">.</span><span class="n">y</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    	<span class="k">if</span> <span class="n">legDistance</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="p">.</span><span class="n">legDistanceThreshold</span><span class="p">:</span>
            <span class="n">humanPositionTemp</span><span class="p">.</span><span class="n">x</span> <span class="o">=</span> <span class="p">(</span><span class="n">firstLeg</span><span class="p">.</span><span class="n">x</span><span class="o">+</span><span class="n">secondLeg</span><span class="p">.</span><span class="n">x</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span>
            <span class="n">humanPositionTemp</span><span class="p">.</span><span class="n">y</span> <span class="o">=</span> <span class="p">(</span><span class="n">firstLeg</span><span class="p">.</span><span class="n">y</span><span class="o">+</span><span class="n">secondLeg</span><span class="p">.</span><span class="n">y</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span>
            <span class="n">humanPositionTemp</span><span class="p">.</span><span class="n">z</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">twoLegsDetected</span> <span class="o">=</span> <span class="bp">True</span>
    	<span class="k">else</span><span class="p">:</span>
            <span class="n">humanPositionTemp</span> <span class="o">=</span> <span class="n">firstLeg</span>
    <span class="k">else</span><span class="p">:</span>
    	<span class="n">humanPositionTemp</span> <span class="o">=</span> <span class="n">firstLeg</span>
    <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">positionCalibration</span><span class="p">:</span>
    	<span class="n">r</span> <span class="o">=</span> <span class="n">math</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span> <span class="n">humanPositionTemp</span><span class="p">.</span><span class="n">x</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">+</span> <span class="n">humanPositionTemp</span><span class="p">.</span><span class="n">y</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
    	<span class="k">if</span> <span class="n">r</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="p">.</span><span class="n">calibrationDistance</span> <span class="ow">and</span> <span class="n">twoLegsDetected</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">lastHumanPosition</span> <span class="o">=</span> <span class="n">humanPositionTemp</span>
            <span class="n">humanPosition</span> <span class="o">=</span> <span class="n">humanPositionTemp</span>
            <span class="n">firstLegDetected</span> <span class="o">=</span> <span class="bp">True</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">lastDetectionTime</span> <span class="o">=</span> <span class="n">rospy</span><span class="p">.</span><span class="n">get_time</span><span class="p">()</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">positionCalibration</span> <span class="o">=</span> <span class="bp">False</span>
            <span class="n">led</span> <span class="o">=</span> <span class="n">Bool</span><span class="p">()</span>
            <span class="n">led</span><span class="p">.</span><span class="n">data</span> <span class="o">=</span> <span class="bp">True</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">ledPub</span><span class="p">.</span><span class="n">publish</span><span class="p">(</span><span class="n">led</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
    	<span class="n">distanceChange</span> <span class="o">=</span> <span class="n">math</span><span class="p">.</span><span class="n">sqrt</span><span class="p">((</span><span class="bp">self</span><span class="p">.</span><span class="n">lastHumanPosition</span><span class="p">.</span><span class="n">x</span> <span class="o">-</span> <span class="n">humanPositionTemp</span><span class="p">.</span><span class="n">x</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> \
    				<span class="o">+</span> <span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">lastHumanPosition</span><span class="p">.</span><span class="n">y</span> <span class="o">-</span> <span class="n">humanPositionTemp</span><span class="p">.</span><span class="n">y</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    	<span class="k">if</span> <span class="n">distanceChange</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="p">.</span><span class="n">humanPositionChangeThreshold</span><span class="p">:</span>
            <span class="n">humanPosition</span> <span class="o">=</span> <span class="n">humanPositionTemp</span>
            <span class="n">firstLegDetected</span> <span class="o">=</span> <span class="bp">True</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">lastHumanPosition</span> <span class="o">=</span> <span class="n">humanPosition</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">lastDetectionTime</span> <span class="o">=</span> <span class="n">rospy</span><span class="p">.</span><span class="n">get_time</span><span class="p">()</span>
    	<span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">rospy</span><span class="p">.</span><span class="n">get_time</span><span class="p">()</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">lastDetectionTime</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="p">.</span><span class="n">detectionTimeout</span><span class="p">:</span>
                <span class="n">humanPosition</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">lastHumanPosition</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">led</span> <span class="o">=</span> <span class="n">Bool</span><span class="p">()</span>
                <span class="n">led</span><span class="p">.</span><span class="n">data</span> <span class="o">=</span> <span class="bp">False</span>
                <span class="bp">self</span><span class="p">.</span><span class="n">ledPub</span><span class="p">.</span><span class="n">publish</span><span class="p">(</span><span class="n">led</span><span class="p">)</span>
                <span class="bp">self</span><span class="p">.</span><span class="n">positionCalibration</span> <span class="o">=</span> <span class="bp">True</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">firstLeg</span><span class="p">,</span> <span class="n">secondLeg</span><span class="p">,</span> <span class="n">humanPosition</span><span class="p">,</span> <span class="n">firstLegDetected</span><span class="p">,</span> <span class="n">twoLegsDetected</span><span class="p">)</span>
</code></pre></div></div>

<p>We assume our first detected leg is one closest to ROSbot. Second leg (if any available) is one closest to first leg (if it’s close enough). With two legs detected we calculate possible human position as mean between legs, otherwise we use first leg as possible human position.<br />
When human position is not calibrated, then two legs have to be visible in range closer than given threshold. Provided that our position is already calibrated, we can check if our detected human position is viable. We calculate difference in positions between new and old detection, too big value means that it’s probably false detection. In this case we check if we can use older position, otherwise we lost track of human position.</p>

<ul>
  <li><strong>legDistanceThreshold</strong> - maximum distance from first leg to second leg, if second leg distance is more than that, we use only first leg detection</li>
  <li><strong>calibrationDistance</strong> - maximum distance from human to ROSbot to initialize position</li>
  <li><strong>humanPositionChangeThreshold</strong> - maximum distance between last detected human position and recent human position</li>
  <li><strong>detectionTimeout</strong> - how much time we can use old detection as human position, if we exceed this time we consider that we lost our human detection</li>
</ul>

<h3 id="4-marker-publishing">4. Marker publishing</h3>

<p>Visualization of our detections</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">scanCallback</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scan</span><span class="p">):</span>
    <span class="p">...</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">publishMarkers</span><span class="p">(</span><span class="n">firstLeg</span><span class="p">,</span> <span class="n">secondLeg</span><span class="p">,</span> <span class="n">humanPosition</span><span class="p">,</span> <span class="n">firstLegDetected</span><span class="p">,</span> <span class="n">twoLegsDetected</span><span class="p">,</span> <span class="n">sortedClusters</span><span class="p">)</span>
    <span class="p">...</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">publishMarkers</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">firstLeg</span><span class="p">,</span> <span class="n">secondLeg</span><span class="p">,</span> <span class="n">humanPosition</span><span class="p">,</span> <span class="n">firstLegDetected</span><span class="p">,</span> <span class="n">twoLegsDetected</span><span class="p">,</span> <span class="n">sortedClusters</span><span class="p">):</span>
    <span class="n">legMarker</span> <span class="o">=</span> <span class="n">Marker</span><span class="p">()</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">header</span><span class="p">.</span><span class="n">frame_id</span> <span class="o">=</span> <span class="s">"laser"</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">ns</span> <span class="o">=</span> <span class="s">"person"</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">header</span><span class="p">.</span><span class="n">stamp</span> <span class="o">=</span> <span class="n">rospy</span><span class="p">.</span><span class="n">Time</span><span class="p">()</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="nb">type</span> <span class="o">=</span> <span class="n">Marker</span><span class="p">.</span><span class="n">CYLINDER</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">action</span> <span class="o">=</span> <span class="n">Marker</span><span class="p">.</span><span class="n">ADD</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">pose</span><span class="p">.</span><span class="n">orientation</span><span class="p">.</span><span class="n">x</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">pose</span><span class="p">.</span><span class="n">orientation</span><span class="p">.</span><span class="n">y</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">pose</span><span class="p">.</span><span class="n">orientation</span><span class="p">.</span><span class="n">z</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">pose</span><span class="p">.</span><span class="n">orientation</span><span class="p">.</span><span class="n">w</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">scale</span><span class="p">.</span><span class="n">x</span> <span class="o">=</span> <span class="mf">0.04</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">scale</span><span class="p">.</span><span class="n">y</span> <span class="o">=</span> <span class="mf">0.04</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">scale</span><span class="p">.</span><span class="n">z</span> <span class="o">=</span> <span class="mf">0.04</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">color</span><span class="p">.</span><span class="n">a</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">color</span><span class="p">.</span><span class="n">r</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">color</span><span class="p">.</span><span class="n">g</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">color</span><span class="p">.</span><span class="n">b</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">lifetime</span> <span class="o">=</span> <span class="n">rospy</span><span class="p">.</span><span class="n">Duration</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="p">.</span><span class="n">positionCalibration</span><span class="p">:</span>
    	<span class="c1">#first leg
</span>        <span class="k">if</span> <span class="n">firstLegDetected</span><span class="p">:</span>
            <span class="n">legMarker</span><span class="p">.</span><span class="nb">id</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="n">legMarker</span><span class="p">.</span><span class="n">pose</span><span class="p">.</span><span class="n">position</span> <span class="o">=</span> <span class="n">firstLeg</span>
            <span class="n">legMarker</span><span class="p">.</span><span class="n">pose</span><span class="p">.</span><span class="n">position</span><span class="p">.</span><span class="n">z</span> <span class="o">=</span> <span class="mf">0.02</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">legPub</span><span class="p">.</span><span class="n">publish</span><span class="p">(</span><span class="n">legMarker</span><span class="p">)</span>
        <span class="c1">#second leg
</span>        <span class="k">if</span> <span class="n">twoLegsDetected</span><span class="p">:</span>
            <span class="n">legMarker</span><span class="p">.</span><span class="nb">id</span> <span class="o">=</span> <span class="mi">2</span>
            <span class="n">legMarker</span><span class="p">.</span><span class="n">pose</span><span class="p">.</span><span class="n">position</span> <span class="o">=</span> <span class="n">secondLeg</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">legPub</span><span class="p">.</span><span class="n">publish</span><span class="p">(</span><span class="n">legMarker</span><span class="p">)</span>
    	<span class="c1">#human position
</span>    	<span class="n">legMarker</span><span class="p">.</span><span class="nb">id</span> <span class="o">=</span> <span class="mi">3</span>
    	<span class="n">legMarker</span><span class="p">.</span><span class="n">scale</span><span class="p">.</span><span class="n">z</span> <span class="o">=</span> <span class="mf">0.2</span>
    	<span class="n">legMarker</span><span class="p">.</span><span class="n">pose</span><span class="p">.</span><span class="n">position</span> <span class="o">=</span> <span class="n">humanPosition</span>
    	<span class="n">legMarker</span><span class="p">.</span><span class="n">pose</span><span class="p">.</span><span class="n">position</span><span class="p">.</span><span class="n">z</span> <span class="o">=</span> <span class="mf">0.1</span>
    	<span class="n">legMarker</span><span class="p">.</span><span class="n">color</span><span class="p">.</span><span class="n">r</span> <span class="o">=</span> <span class="mf">1.0</span>
    	<span class="n">legMarker</span><span class="p">.</span><span class="n">color</span><span class="p">.</span><span class="n">b</span> <span class="o">=</span> <span class="mf">0.0</span>
    	<span class="bp">self</span><span class="p">.</span><span class="n">legPub</span><span class="p">.</span><span class="n">publish</span><span class="p">(</span><span class="n">legMarker</span><span class="p">)</span>
    <span class="n">legMarker</span> <span class="o">=</span> <span class="n">Marker</span><span class="p">()</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">ns</span> <span class="o">=</span> <span class="s">"legs"</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">header</span><span class="p">.</span><span class="n">frame_id</span> <span class="o">=</span> <span class="s">"laser"</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">header</span><span class="p">.</span><span class="n">stamp</span> <span class="o">=</span> <span class="n">rospy</span><span class="p">.</span><span class="n">Time</span><span class="p">()</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="nb">type</span> <span class="o">=</span> <span class="n">Marker</span><span class="p">.</span><span class="n">SPHERE</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">action</span> <span class="o">=</span> <span class="n">Marker</span><span class="p">.</span><span class="n">ADD</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">pose</span><span class="p">.</span><span class="n">orientation</span><span class="p">.</span><span class="n">x</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">pose</span><span class="p">.</span><span class="n">orientation</span><span class="p">.</span><span class="n">y</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">pose</span><span class="p">.</span><span class="n">orientation</span><span class="p">.</span><span class="n">z</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">pose</span><span class="p">.</span><span class="n">orientation</span><span class="p">.</span><span class="n">w</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">scale</span><span class="p">.</span><span class="n">x</span> <span class="o">=</span> <span class="mf">0.04</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">scale</span><span class="p">.</span><span class="n">y</span> <span class="o">=</span> <span class="mf">0.04</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">scale</span><span class="p">.</span><span class="n">z</span> <span class="o">=</span> <span class="mf">0.04</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">color</span><span class="p">.</span><span class="n">a</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">color</span><span class="p">.</span><span class="n">r</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">color</span><span class="p">.</span><span class="n">g</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">color</span><span class="p">.</span><span class="n">b</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">lifetime</span> <span class="o">=</span> <span class="n">rospy</span><span class="p">.</span><span class="n">Duration</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)</span>
    <span class="n">i</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">sortedClusters</span><span class="p">:</span>
    	<span class="n">legMarker</span><span class="p">.</span><span class="nb">id</span> <span class="o">=</span> <span class="n">i</span>
    	<span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
    	<span class="n">legMarker</span><span class="p">.</span><span class="n">pose</span><span class="p">.</span><span class="n">position</span><span class="p">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">x</span>
    	<span class="n">legMarker</span><span class="p">.</span><span class="n">pose</span><span class="p">.</span><span class="n">position</span><span class="p">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">y</span>
    	<span class="bp">self</span><span class="p">.</span><span class="n">legPub</span><span class="p">.</span><span class="n">publish</span><span class="p">(</span><span class="n">legMarker</span><span class="p">)</span>
</code></pre></div></div>

<p>Pretty straightforward: we publish markers with potential legs (green spheres), detected legs (if any found, blue cylinders) and human (red cylinder).</p>

<h3 id="5-control">5. Control</h3>

<p>And final step is movement control:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">scanCallback</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scan</span><span class="p">):</span>
    <span class="p">...</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">controlRosbot</span><span class="p">(</span><span class="n">humanPosition</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">controlRosbot</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">humanPosition</span><span class="p">):</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">math</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span> <span class="n">humanPosition</span><span class="p">.</span><span class="n">x</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">+</span> <span class="n">humanPosition</span><span class="p">.</span><span class="n">y</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">math</span><span class="p">.</span><span class="n">atan2</span><span class="p">(</span><span class="n">humanPosition</span><span class="p">.</span><span class="n">y</span><span class="p">,</span> <span class="o">-</span><span class="n">humanPosition</span><span class="p">.</span><span class="n">x</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">r</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="p">.</span><span class="n">minHumanDistance</span><span class="p">:</span>
    	<span class="n">xSpeed</span> <span class="o">=</span> <span class="o">-</span><span class="n">r</span> <span class="o">*</span> <span class="bp">self</span><span class="p">.</span><span class="n">speedPGain</span>
    <span class="k">else</span><span class="p">:</span>
    	<span class="n">xSpeed</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="p">.</span><span class="n">minHumanAngle</span><span class="p">:</span>
    	<span class="n">zAngularSpeed</span> <span class="o">=</span> <span class="n">a</span> <span class="o">*</span> <span class="bp">self</span><span class="p">.</span><span class="n">angularSpeedPGain</span>
    <span class="k">else</span><span class="p">:</span>
    	<span class="n">zAngularSpeed</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">rosbotControl</span> <span class="o">=</span> <span class="n">Twist</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">rospy</span><span class="p">.</span><span class="n">get_time</span><span class="p">()</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">buttonTime</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="p">.</span><span class="n">buttonTimeout</span> <span class="ow">and</span> \
    		<span class="bp">self</span><span class="p">.</span><span class="n">buttonState</span> <span class="o">==</span> <span class="bp">True</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="p">.</span><span class="n">positionCalibration</span><span class="p">:</span>
    	<span class="n">rosbotControl</span><span class="p">.</span><span class="n">linear</span><span class="p">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">xSpeed</span>
    	<span class="n">rosbotControl</span><span class="p">.</span><span class="n">angular</span><span class="p">.</span><span class="n">z</span> <span class="o">=</span> <span class="n">zAngularSpeed</span>
    	<span class="bp">self</span><span class="p">.</span><span class="n">speedPub</span><span class="p">.</span><span class="n">publish</span><span class="p">(</span><span class="n">rosbotControl</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
    	<span class="bp">self</span><span class="p">.</span><span class="n">speedPub</span><span class="p">.</span><span class="n">publish</span><span class="p">(</span><span class="n">rosbotControl</span><span class="p">)</span>
</code></pre></div></div>

<p>Firstly we convert our cartesian coordinates to polar ones. Then we calculate angular and linear speed for ROSbot with proportional controller. We publish it if we receive message from remote that allow robot to move.</p>

<ul>
  <li><strong>minHumanDistance</strong> - if human distance is more than that robot will start following</li>
  <li><strong>minHumanAngle</strong> - if human angle is more than that robot will start following</li>
  <li><strong>speedPGain</strong> - proportional gain for linear ROSbot speed (increase if you want your robot to go faster)</li>
  <li><strong>angularSpeedPGain</strong> - proportional gain for angular ROSbot speed (increase if you want your robot to turn faster)</li>
  <li><strong>buttonTimeout</strong> (seconds) - if we don’t receive new Dead Man’s Button message for that time ROSbot isn’t allowed to move</li>
</ul>

<h3 id="followerkalman">FollowerKalman</h3>

<p>This version is improved slow follower - basically only additions are scoring system and Kalman filter. Also I changed some parameters to make it more suitable for higher speeds.<br />
In order to implement Kalman filter I created Person class where human position is stored and updated. For Kalman Filter part I used code from <a href="https://github.com/angusleigh/leg_tracker">leg_tracker</a>. All the parameters for filter were well tuned, I only changed std_obs value.</p>

<ul>
  <li><strong>std_obs</strong> - increasing this value means you don’t trust your measurements and as the effect your data is much more filtered. Be careful with changing it too much, because it causes your estimated human position to be slower to sudden changes - if you stop, filter won’t trust as much your readings and as a result it will predict you will still move with some velocity. Consequently robot will continue moving forward and it will take some time to adjust to reality. On the other hand if you decrease it too much human position will fluctuate with uncertainties in leg detections.</li>
</ul>

<p>Next big change is that I added scoring system which uses all parameters: proportion, area, length and distance. It combines it with appropriate weights.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">proportion</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">xDistance</span><span class="p">,</span><span class="n">yDistance</span><span class="p">)</span><span class="o">/</span><span class="nb">min</span><span class="p">(</span><span class="n">xDistance</span><span class="p">,</span> <span class="n">yDistance</span><span class="p">)</span>
<span class="n">area</span> <span class="o">=</span> <span class="n">xDistance</span><span class="o">*</span><span class="n">yDistance</span>
<span class="n">widthDifference</span> <span class="o">=</span> <span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">xDistance</span><span class="p">,</span><span class="n">yDistance</span><span class="p">)</span><span class="o">-</span><span class="bp">self</span><span class="p">.</span><span class="n">legWidth</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">dLegWidth</span>
<span class="n">distanceFromRobot</span> <span class="o">=</span> <span class="n">math</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">xMean</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">yMean</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="n">score</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">score</span> <span class="o">+=</span> <span class="n">distanceFromRobot</span> <span class="o">*</span> <span class="bp">self</span><span class="p">.</span><span class="n">distanceWeight</span>
<span class="n">score</span> <span class="o">+=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">proportion</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">destProportion</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="p">.</span><span class="n">proportionWeight</span>
<span class="n">score</span> <span class="o">+=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">area</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">destArea</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="p">.</span><span class="n">areaWeight</span>
<span class="k">if</span> <span class="n">widthDifference</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">score</span> <span class="o">+=</span> <span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">widthDifference</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="p">.</span><span class="n">widthDifferenceWeight</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
<span class="k">if</span> <span class="n">score</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="p">.</span><span class="n">maxScore</span><span class="p">:</span>
    <span class="n">sortedClustersDetails</span><span class="p">.</span><span class="n">append</span><span class="p">([</span><span class="n">xMean</span><span class="p">,</span> <span class="n">yMean</span><span class="p">,</span> <span class="n">distanceFromRobot</span><span class="p">,</span> <span class="n">proportion</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">widthDifference</span><span class="p">,</span> <span class="n">score</span><span class="p">])</span>
</code></pre></div></div>

<p>Parameters:</p>

<ul>
  <li><strong>destProportion</strong> - our desired proportion, I set it based on readings I got</li>
  <li><strong>destArea</strong> - same as above but with area</li>
  <li><strong>distanceWeight</strong> - weight we give to distance from robot</li>
  <li><strong>proportionWeight</strong> - weight we set to distance between measured proportion and desired</li>
  <li><strong>areaWeight</strong> - don’t set this weight too high, as it is not as reliable</li>
  <li><strong>widthDifferenceWeight</strong> - we set it really high, because when reading is too long, then it’s probably not a leg</li>
  <li><strong>maxScore</strong> - above that score we are certain that detection isn’t a leg</li>
</ul>

<p>Parameters with updated values:</p>

<ul>
  <li><strong>minRange</strong> (increased) - robot has to detect obstacles earlier</li>
  <li><strong>speedPGain</strong> (increased) - increase in proportional gain to obtain higher speed</li>
  <li><strong>angularSpeedPGain</strong> (increased) - same as above</li>
  <li><strong>minHumanDistance</strong> (decreased) - robot will start following earlier and be able to keep up with human</li>
  <li><strong>humanPositionChangeThreshold</strong> (increased) - person walks faster so position can change more</li>
  <li><strong>detectionTimeout</strong> (decreased) - higher speeds, so we decrease timeouts</li>
  <li><strong>buttonTimeout</strong> (decreased) - same as above</li>
</ul>

<p>Lastly I added restrictions on obstacle detect - we only detect obstacle approximately in area where we can drive. Increasing minRange can cause ROSbot to be unable to move in narrow spaces.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">if</span> <span class="p">(</span><span class="n">alfa</span> <span class="o">&gt;</span> <span class="o">-</span><span class="n">math</span><span class="p">.</span><span class="n">pi</span> <span class="ow">and</span> <span class="n">alfa</span> <span class="o">&lt;</span> <span class="o">-</span><span class="bp">self</span><span class="p">.</span><span class="n">maxAngle</span><span class="p">)</span> <span class="ow">or</span> \
	<span class="p">(</span><span class="n">alfa</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="p">.</span><span class="n">maxAngle</span> <span class="ow">and</span> <span class="n">alfa</span> <span class="o">&lt;</span> <span class="n">math</span><span class="p">.</span><span class="n">pi</span><span class="p">):</span>
</code></pre></div></div>

<h2 id="summary">Summary</h2>

<p>In this tutorial you learned how to set up and run human following using ROSbot with ESP remote. After main algorithm walkthrough you should be also able to modify it to suit your robot.</p>]]></content><author><name></name></author><category term="Roboty" /><summary type="html"><![CDATA[Every move you make | Every step you take | I'll follow you]]></summary></entry><entry><title type="html">Czołg</title><link href="http://localhost:4000/roboty/2019/03/27/tank/" rel="alternate" type="text/html" title="Czołg" /><published>2019-03-27T00:00:00+01:00</published><updated>2019-03-27T00:00:00+01:00</updated><id>http://localhost:4000/roboty/2019/03/27/tank</id><content type="html" xml:base="http://localhost:4000/roboty/2019/03/27/tank/"><![CDATA[<p>Pojazd uniwersalny oparty o Raspberry Pi Zero.</p>

<figure class="figure  figure--center">
  <img class="image" src="/pics/Czolg/front.jpg" alt="" width="600" height="800" />
  
</figure>

<p>Umożliwia obserwację obrazu z kamerki, odczyt napięcia na baterii (poziom rozładowania ), temperatury z Raspberry oraz wartości enkoderów. Dotychczas odczytów z enkoderów nie wykorzystałem w sposób praktyczny, jednak zamieszczenie ich umożliwi dalszy rozwój konstrukcji.</p>

<div class="embed-container">
  <iframe width="720" height="405" src="https://drive.google.com/file/d/1QSsrb819J34oQ7zTbSGpt-7YVE9Y9KgX/preview" frameborder="0" allowfullscreen="">
  </iframe>
</div>

<p>Projekt ten zaczął się od płytki PCB.</p>
<figure class="figure  figure--center">
  <img class="image" src="/pics/Czolg/pierwotna.jpg" alt="Płytka wraz z podłączonymi wszystkimi elementami" width="600" height="800" />
  <figcaption class="caption">Płytka wraz z podłączonymi wszystkimi elementami</figcaption>
</figure>

<p>Miała być wykorzystana do sterowania robotem z następującymi elementami:</p>

<ul>
  <li>dwa silniki z enkoderami</li>
  <li>trzy serwa</li>
  <li>komunikacja z Raspberry pooprzez SPI</li>
  <li>pomiar napięcia z baterii</li>
  <li>dwa LEDy ( uruchomienie oraz rozładowanie)</li>
</ul>

<figure class="figure  figure--center">
  <img class="image" src="/pics/Czolg/testowanie.jpg" alt="Złożony schemat prototypowany na płytce stykowej" width="600" height="800" />
  <figcaption class="caption">Złożony schemat prototypowany na płytce stykowej</figcaption>
</figure>

<p>Jako źródło zasilania wykorzystałem LiPola oraz 2 przetwornicę: jedną do logigki oraz drugą do serw. W trakcie realizacji projektu jednak zorientowałem się, że ten mikrokontroler jest za słaby. Było to spowodowane tym, że potrzebowałem 3 kanałów PWM do serw oraz 2 do sterowania prędkością silników. Nie miałem jednak dostępnej takiej liczby, dlatego sygnały PWM dla serw musiałem generować programowo, przez co znacznie wzrosło obciążenie procesora. Doliczając do tego bardzo często przerwania zewnętrzne z dwóch enkoderów, nie byłem w stanie dostarczyć wystarczająco dokładnego przebiegu PWM by sterować serwami. Dlatego ostatecznie pominąłem użycie serw w tym projekcie.</p>

<figure class="figure  figure--center">
  <img class="image" src="/pics/Czolg/plytkawobudowie.jpg" alt="" width="600" height="800" />
  
</figure>

<p>Konstrukcja czołgu została wykonana na drukarce 3D, a jej projekt zaczerpnąłem z
<a href="https://www.thingiverse.com/thing:652851" title="Konstrukcja">https://www.thingiverse.com/thing:652851</a></p>

<figure class="figure  figure--center">
  <img class="image" src="/pics/Czolg/plytka.jpg" alt="Płytka po wytrawieniu" width="600" height="800" />
  <figcaption class="caption">Płytka po wytrawieniu</figcaption>
</figure>

<p>Robotem steruje się poprzez przeglądarkę. W tym celu użyłem skryptu z <a href="https://hackaday.io/project/25092-zerobot-raspberry-pi-zero-fpv-robot/log/97988-the-new-zerobot-pro" title="Skrypt">https://hackaday.io/project/25092-zerobot-raspberry-pi-zero-fpv-robot/log/97988-the-new-zerobot-pro</a>
,który odpowiednio przerobiłem do swoich potrzeb ( zamiana sterowania na takie wykorzystujące SPI).</p>

<p><a class="button" href="https://github.com/macstepien/Tank" style="background: #0366d6">Projekt  <svg width="16" height="16" class="icon  icon--github" role="img" alt="github"><title>github</title><use xlink:href="#github" fill="CurrentColor"></use></svg>
</a></p>]]></content><author><name></name></author><category term="Roboty" /><summary type="html"><![CDATA[Pojazd uniwersalny oparty o Raspberry Pi Zero.]]></summary></entry><entry><title type="html">Hexapod</title><link href="http://localhost:4000/roboty/2018/06/08/hexapod/" rel="alternate" type="text/html" title="Hexapod" /><published>2018-06-08T00:00:00+02:00</published><updated>2018-06-08T00:00:00+02:00</updated><id>http://localhost:4000/roboty/2018/06/08/hexapod</id><content type="html" xml:base="http://localhost:4000/roboty/2018/06/08/hexapod/"><![CDATA[<p>Sześcionogi stwór z kamerkami.</p>

<p>Projekt, którym zajmowałem się przez pierwsze 2 lata studiów w ramach działalności koła naukowego Integra. Moim wkładem było oprogramowanie do sterowania robota oraz stereowizji.</p>

<figure class="figure  figure--center">
  <img class="image" src="/pics/Hexapod/hexi.jpg" alt="" width="600" height="800" />
  
</figure>

<p>Do poruszania konstrukcją wykorzystane zostało 18 serw Hitec po 3 na każdą nogę. Jako główny komputer robota wykorzystalismy Raspberry Pi 2. Komunikowała się ona z sterownikiem serw Pololu poprzez interfejs UART umożliwiając zadawanie odpowiednich pozycji serw. Całą konstrukcję zasila bateria LiPol o pojemności 4000 mAh, co pozwalało na ok. 1h użytkowania robota. Napięcie z akumulatora dostowywaliśmy za pomocą przetwornic (3 do zasilania serw oraz 1 dla Raspberry). Wykorzystaliśmy także przetwornik ADC MCP3008, aby móc mierzyć aktualne napięcie na baterii. Komunikował się on z Raspberry za pomocą SPI, a następnie napięcie było wysyłane i wyświetlane w aplikacji klienta.</p>

<div class="embed-container">
  <iframe width="720" height="405" src="https://drive.google.com/file/d/1kR9fSGo-6mLM5SdvNPUtoAvgJeeI8Lu-/preview" frameborder="0" allowfullscreen="">
  </iframe>
</div>

<p>Robot jest sterowany z poziomu laptopa, który komunikuje się z Raspberry poprzez WiFi przez protokół TCP. Do poruszania robotem można używać zarówno pada jak i klawiatury. W celu odpowiedniego sterowania najpierw napisałem aplikację obrazującą model matematyczny robota. Na tym modelu została zaimplementowana kinematyka odwrotna, na której następnie stworzyłem modele poruszania się robota. Odpowiednio przeliczone uzyskane kąty na sygnały PWM dla serwonapędów były wysyłane do sterownika.</p>

<figure class="figure  figure--center">
  <img class="image" src="/pics/Hexapod/symulacja.png" alt="" width="600" height="800" />
  
</figure>

<h2 id="sterowanie-robotem">Sterowanie robotem</h2>

<p>Aplikacja uruchamiana na laptopie zawiera wizualizacje modelu robota oraz odbiera sygnały sterowania od użytkownika, które następnie przekazuje do programu na Raspberry. On natomiast dokonuje odpowiednich przeliczeń na sygnały PWM, które następnie przekazuje do sterownika serw. Z Raspberry wysyłana jest także informacja zwrotna do aplikacji użytkownika z aktualnym napięciem na baterii, dzięki czemu jej poziom jest na bieżąco monitorowany. Osobny program służy do realizacji stereowizji. Raspberry wysyła obrazy z obu kamer przy użyciu programu gstreamer. Na laptopie oba obrazy są odbierane i następnie przy użyciu odpowiednich macierzy (uzyskanych podczas kalibracji) przekształcana oraz liczona jest macierz obrazu dysparcji. Zastosowałem także filtr po przeliczeniu dysparcji, który dodatkowo poprawia rezultaty.</p>

<p>Aplikacje modelu Hexapoda można pracować w 2 trybach:</p>

<h4 id="tryb-modelu">Tryb modelu</h4>

<p>W trybie modelu można poruszać się po środowisku za pomocą klawiszy W/S/A/D/Q/E oraz barów alfa, beta i gamma służących do zmiany kąta widzenia. Modelem robota poruszać można za pomocą klawiszy w/s/a/d/q/e oraz numerów służących do wyboru odpowiedniego trybu chodzenia robota.</p>

<div class="embed-container">
  <iframe width="720" height="405" src="https://drive.google.com/file/d/1ixW05vog_nNaR9UR6ZqT5rZBkIWlBJeN/preview" frameborder="0" allowfullscreen="">
  </iframe>
</div>

<h4 id="tryb-połączenia-z-hexapodem">Tryb połączenia z Hexapodem</h4>

<p>Uruchamia się jeśli dodatkowo przekażemy do programu przy uruchomieniu adres IP Raspberry. Sterowanie aplikacją na laptopie nie zmienia się. Różnica z poprzednio omówionym trybem (tryb modelu) jest taka, iż teraz odpowiednie komendy wysyłane są także do Hexapoda. Dodatkowo wyświetlane na ekranie laptopa jest również napięcie na baterii.</p>

<p>Bliższy opis elementów zrealizowanej aplikacji</p>

<h4 id="gui">GUI</h4>

<p>Zadaniem najbardziej oddalonym od samej idei Hexapoda był moduł wyświetlania, czyli GUI. Do wyświetlania użyto wyłącznie prostego okienkowego trybu wyświetlania dołączonego do biblioteki OpenCV w celu debugowania. Zastosowałem rzutowanie perspektywiczne zgodnie ze wzorami zawartymi w <a href="https://en.wikipedia.org/wiki/3D_projection" title="1">1</a>, aby otrzymać symulację w 3D. Zdefiniowałem płaszczyznę kamery, na którą odbywało się rzutowanie świata 3D symulacji. Dodałęm także przesuwanie płaszczyzną kamery za pomocą przycisków oraz możliwość jej obracania przy pomocy toolbarów.</p>

<h4 id="robot">Robot</h4>

<p>To jest główny moduł odpowiedzialny za obliczenia związane ze sterowaniem robota. Zawarłem w nim implementację kinematyki odwrotnej w podejściu trygonometrycznym opisaną w <a href="https://oscarliang.com/inverse-kinematics-and-trigonometry-basics/" title="2">2</a>. Główna klasa robota zawiera klasę nóg robota, które są wydzielone. Jest osobna klasa, w której znajdują się różne algorytmy chodzenia.</p>

<h4 id="chodzenie">Chodzenie</h4>

<p>Najlepsze efekty dawało chodzenie po paraboli. Dobierane są kolejne punkty paraboli, która zaczyna się w miejscu, gdzie aktualnie znajduje się końcówka nogi robota. Kończy się tam, gdzie ma się ostatecznie znaleźć. Przy użyciu kinematyki odwrotnej wyliczane są kąty tak, aby końcówka danej nogi znalazła się w punkcie docelowym.</p>

<h4 id="pozostałe-moduły">Pozostałe moduły</h4>

<p>Kontroler, który odpowiednio interpretuje wysłane komendy na funkcje, np.: chodzenia lub poruszania bazą robota. Znajduje się tutaj również moduł do komunikacji z serwami (tylko w wersji programu dla Raspberry). Zamieniane są wyliczone kąty dla każdej nogi na odpowiednie sygnały PWM, dla każdego serwa (jedna noga składa się z trzech serwonapędów). Następnie są one wysyłane.</p>

<h4 id="tcp">TCP</h4>

<p>W module TCP znajduję się cały kod do komunikacji pomiędzy Raspberry a laptopem. Kod został zaczerpnięty z <a href="https://github.com/vichargrave/tcpsockets" title="3">3</a>. W ramach komunikacji laptop łączy się z Raspberry i na porcie 8081 odbiera aktualne napięcie baterii, które Raspberry stale udostępnia. Komunikacja w ramach odczytu napięcia baterii odbywa się w osobnym wątku, aby nie zakłócać pozostałych operacji. Natomiast na port 8080 aplikacja z laptopa wysyła podane komendy.</p>

<p><a class="button" href="https://github.com/macstepien/HexapodPC" style="background: #0366d6">Aplikacja na laptopa  <svg width="16" height="16" class="icon  icon--github" role="img" alt="github"><title>github</title><use xlink:href="#github" fill="CurrentColor"></use></svg>
</a></p>

<p><a class="button" href="https://github.com/macstepien/HexapodRaspberry" style="background: #0366d6">Aplikacja na Raspberry  <svg width="16" height="16" class="icon  icon--github" role="img" alt="github"><title>github</title><use xlink:href="#github" fill="CurrentColor"></use></svg>
</a></p>

<h2 id="stereowizja">Stereowizja</h2>

<p>Poniżej przedstawie krótki opis etapów realizacji stereowizji:</p>

<h3 id="wykonanie-zdjęć-kalibracyjnych">Wykonanie zdjęć kalibracyjnych</h3>

<p>Aby skalibrować parę stereowizyjną wykonywane są zdjęcia ustalonego wzoru, np. szachownicy. W tym celu napisałem aplikację, która wyświetlała obraz z obu kamer. Co ustalony czas zapisywała zdjęcie pod odpowiednią nazwą oraz tworzyła listę utworzonych obrazów. Wykonałem około 50 zdjęć tak, aby jak najlepiej pokryć cały obszar widoku kamer.</p>

<figure class="figure  figure--center">
  <img class="image" src="/pics/Hexapod/stereo12.png" alt="Przykładowa para zdjęć wykonanych podczas kalibracji" width="600" height="800" />
  <figcaption class="caption">Przykładowa para zdjęć wykonanych podczas kalibracji</figcaption>
</figure>

<p>Widoczny na zdjęciach zamieszczonych powyżej jest także następny napotkany problem - obiektywy w obudowach kamer zamontowane były nierówno. Oczywiście to przesunięcie eliminowane jest podczas kalibracji, jednak w rezultacie podczas właściwej stereowizji ograniczone jest pole widzenia od góry i dołu (część pixeli widoczna jest tylko przez jedną kamerkę).</p>

<h3 id="kalibracja">Kalibracja</h3>

<p>Do samej kalibracji użyłem przykładu z książki Learning OpenCV. W parametrach wywołania umieszczano wysokość oraz szerokość szachownicy (liczba pól), a także długość boku kwadratu w centymetrach. Bardzo ważne jest, aby szachownica miała kwadratowe pola, gdyż przy użyciu szachownicy o bokach różniących się nieznacznie cały proces kalibracji zostałby przeprowadzony niepoprawnie wraz z listą zdjęć, powstałych w trakcie tej błędnej kalibracji.</p>

<figure class="figure  figure--center">
  <img class="image" src="/pics/Hexapod/stereo3.png" alt="Wynik wykrywania krawędzi szachownicy" width="400" height="800" />
  <figcaption class="caption">Wynik wykrywania krawędzi szachownicy</figcaption>
</figure>

<figure class="figure  figure--center">
  <img class="image" src="/pics/Hexapod/stereo4.png" alt="Wynik rektyfikacji" width="700" height="800" />
  <figcaption class="caption">Wynik rektyfikacji</figcaption>
</figure>

<p>W wyniku działania kalibracji otrzymałem parametry zewnętrzne oraz wewnętrzne kamer, które następnie używane były do właściwej stereowizji. Uzyskano błędy:
błąd średniokwadratowy (RMS) = 0.0503053
średni błąd epipolarny = 0.517146
Są to wartości niskie, co świadczy o poprawnie wykonanej kalibracji.</p>

<h3 id="wybór-algorytmu-oraz-dobranie-parametrów">Wybór algorytmu oraz dobranie parametrów</h3>

<p>Najpierw przetestowałem dostępne w bibliotece OpenCV algorytmy BM i SGBM, lepsze rezultaty uzyskałem dla SGBM. Jest on bardziej wymagający obliczeniowo, aczkolwiek przy rozdzielczości 320x240 można było uzyskać dobre przetwarzanie w czasie rzeczywistym. Następnie dobrałem optymalne parametry dla tego algorytmu. W tym celu napisałem aplikację na podstawie przykładu użycia SGBM zawartego w bibliotece OpenCV. Dodałem do niej suwak tak, aby można było wygodnie zmieniać parametry i obserwować uzyskiwane rezultatu.</p>

<figure class="figure  figure--center">
  <img class="image" src="/pics/Hexapod/stereo5.png" alt="Widok okna z paskami do zmiany parametrów" width="400" height="800" />
  <figcaption class="caption">Widok okna z paskami do zmiany parametrów</figcaption>
</figure>

<figure class="figure  figure--center">
  <img class="image" src="/pics/Hexapod/stereo6.png" alt="Przykładowa scena użyta do doboru parametrów" width="400" height="800" />
  <figcaption class="caption">Przykładowa scena użyta do doboru parametrów</figcaption>
</figure>

<figure class="figure  figure--center">
  <img class="image" src="/pics/Hexapod/stereo7.png" alt="Wynik przeprowadzenia stereowizji" width="400" height="800" />
  <figcaption class="caption">Wynik przeprowadzenia stereowizji</figcaption>
</figure>

<h3 id="dobranie-parametrów-dla-postfiltracji">Dobranie parametrów dla postfiltracji</h3>

<p>W celu uzyskania gładszego obrazu stereowizyjnego zastosowałem postfiltrację, która dodana została stosunkowo niedawno do modułów dodatkowych biblioteki OpenCV - contrib.</p>

<figure class="figure  figure--center">
  <img class="image" src="/pics/Hexapod/stereo9.png" alt="Efekt przeprowadzenia algorytmu SGBM przy optymalnych parametrach" width="400" height="800" />
  <figcaption class="caption">Efekt przeprowadzenia algorytmu SGBM przy optymalnych parametrach</figcaption>
</figure>

<figure class="figure  figure--center">
  <img class="image" src="/pics/Hexapod/stereo10.png" alt="Efekt przeprowadzenia postfiltracji" width="400" height="800" />
  <figcaption class="caption">Efekt przeprowadzenia postfiltracji</figcaption>
</figure>

<h3 id="ostateczna-aplikacja">Ostateczna aplikacja</h3>

<p>W ostatecznej aplikacji połączone zostały wszystkie opisane elementy. W wyniku czego otrzymano przesył obrazu z obu kamer na laptopa. Tam obraz był rektyfikowany, a pixele były dopasowywane za pomocą algorytmu SGBM. Przy użyciu posfiltracji obraz dysparcji jest poprawiany i na koniec wyświetlany. Dalszym etapem rozwojowym może być przeliczenie chmury punktów na podstawie dysparcji oraz następnie wykrywanie i omijanie przeszkód.</p>

<p>Poza samą realizacją stereowizji ważnym elementem był także optymalny przesył obrazu z obu kamer. Pierwszym podejściem było użycie MJPGstreamera. Efekty jednak nie były zadowalające. Klatki, które nie zostały jeszcze wysłane, były składowane w buforze. W wyniku czego, im dłużej działała aplikacja, tym większe było opóźnienie. Dodatkowo występowała różnica czasu pomiędzy klatkami z obu kamer, co w przypadku stereowizji jest nieakceptowalne. Dlatego zdecydowano się użyć gstreamera. Jest on bardziej zaawansowany, przez co uruchomienie go zajęło więcej czasu. Jednak uzyskany efekt jest bardzo dobry. W jego działaniu, jeśli nie zdąży się wysłać klatki przed przybyciem następnej, to zostaje ona porzucona. W wyniku tego wyeliminowane zostało rosnące opóźnienie. Dlatego też nie występowało już opóźnienie pomiędzy klatkami. Rozdzielczość przesyłanych obrazów wynosi 320x240. Przeprowadzono także testy dla rozdzielczości 640x480, ale spadek FPS był nieproporcjonalny do wzrostu jakości.</p>

<p><a class="button" href="https://github.com/macstepien/HexapodStereovision" style="background: #0366d6">Stereowizja  <svg width="16" height="16" class="icon  icon--github" role="img" alt="github"><title>github</title><use xlink:href="#github" fill="CurrentColor"></use></svg>
</a></p>

<h3 id="osiągnięcia">Osiągnięcia</h3>

<h4 id="zawody-robotyczne">Zawody robotyczne</h4>

<ul>
  <li>Robocomp 2017 w Krakowie (kategoria Freestyle)</li>
  <li>Robotic Arena 2017 we Wrocławiu (kategorie Freestyle oraz wyścig robotów kroczących). Pierwsze miejsce w kategorii wyścig robotów kroczących.</li>
  <li>Robomaticon 2018 w Warszawie (kategoria Freestyle)</li>
  <li>Robotic Tournament 2018 w Rybniku (kategoria Freestyle)</li>
  <li>Robotic Arena 2019 we Wrocławiu. Drugie miejsce w kategorii wyścig robotów kroczących.</li>
</ul>

<h4 id="wydarzenia">Wydarzenia</h4>

<ul>
  <li>Targi pracy Kariera IT</li>
  <li>TEDxAGHUniversity</li>
</ul>

<figure class="figure  figure--center">
  <img class="image" src="/pics/Hexapod/robotic_arena.jpg" alt="Prezentacja na zawodach Robotic Arena fot. Politechnika Wrocławska" width="400" height="800" />
  <figcaption class="caption">Prezentacja na zawodach Robotic Arena fot. Politechnika Wrocławska</figcaption>
</figure>

<p><a href="http://www.integra.agh.edu.pl/robot-kroczacy-freestyle/" title="Strona projektu">Strona projektu</a></p>]]></content><author><name></name></author><category term="Roboty" /><summary type="html"><![CDATA[Sześcionogi stwór z kamerkami.]]></summary></entry><entry><title type="html">Świecąca kulka</title><link href="http://localhost:4000/oprogramowanie/2017/05/26/move/" rel="alternate" type="text/html" title="Świecąca kulka" /><published>2017-05-26T00:00:00+02:00</published><updated>2017-05-26T00:00:00+02:00</updated><id>http://localhost:4000/oprogramowanie/2017/05/26/move</id><content type="html" xml:base="http://localhost:4000/oprogramowanie/2017/05/26/move/"><![CDATA[<p>Obsługa komputera poprzez ruchy kontrolerem.</p>

<figure class="figure  figure--center">
  <img class="image" src="/pics/swiecacaKulka/kontroler.jpg" alt="" width="300" height="300" />
  
</figure>

<p>Kontroler zainspirowany rozwiązaniem z PlayStation. Użyłem kamerki internetowej oraz odpowiedniego kontrolera - latarki z kulką. Ruchy kulki są śledzone oraz przekładane na ruchy kursora myszy. Poprzez odpowiednie przygaszenie a następnie zaświecenie latarki symulowane jest kliknięcie.</p>

<p>W celu analizy obrazu użyłem bibliotekę OpenCV oraz metodę wykrywania przedstawioną w <a href="https://forbot.pl/blog/opencv-2-wykrywanie-obiektow-id4888">https://forbot.pl/blog/opencv-2-wykrywanie-obiektow-id4888</a></p>

<div class="embed-container">
  <iframe width="720" height="405" src="https://drive.google.com/file/d/1Ifl4nigfpzm73YRJDlyJJY3RQRywG9NQ/preview" frameborder="0" allowfullscreen="">
  </iframe>
</div>

<p><a class="button" href="https://github.com/macstepien/LightOrb" style="background: #0366d6">Kod  <svg width="16" height="16" class="icon  icon--github" role="img" alt="github"><title>github</title><use xlink:href="#github" fill="CurrentColor"></use></svg>
</a></p>]]></content><author><name></name></author><category term="Oprogramowanie" /><summary type="html"><![CDATA[Obsługa komputera poprzez ruchy kontrolerem.]]></summary></entry><entry><title type="html">Efekt gitarowy Fuzz</title><link href="http://localhost:4000/elektronika/2016/08/28/fuzz/" rel="alternate" type="text/html" title="Efekt gitarowy Fuzz" /><published>2016-08-28T00:00:00+02:00</published><updated>2016-08-28T00:00:00+02:00</updated><id>http://localhost:4000/elektronika/2016/08/28/fuzz</id><content type="html" xml:base="http://localhost:4000/elektronika/2016/08/28/fuzz/"><![CDATA[<figure class="figure  figure--center">
  <img class="image" src="/pics/fuzz/front.jpg" alt="" width="600" height="" />
  
</figure>

<p>Efekt gitarowy wykonany na podstawie schematu:</p>
<figure class="figure  figure--center">
  <img class="image" src="/pics/fuzz/fuzzSchemat.gif" alt="" width="600" height="800" />
  
</figure>

<figure class="figure  figure--center">
  <img class="image" src="/pics/fuzz/inside.jpg" alt="" width="600" height="" />
  
</figure>]]></content><author><name></name></author><category term="Elektronika" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Cewka Tesli</title><link href="http://localhost:4000/elektronika/2015/12/10/cewkatesli/" rel="alternate" type="text/html" title="Cewka Tesli" /><published>2015-12-10T00:00:00+01:00</published><updated>2015-12-10T00:00:00+01:00</updated><id>http://localhost:4000/elektronika/2015/12/10/cewkatesli</id><content type="html" xml:base="http://localhost:4000/elektronika/2015/12/10/cewkatesli/"><![CDATA[<p>Robi się groźnie.</p>

<figure class="figure  figure--center">
  <img class="image" src="/pics/cewkatesli/wieksza.jpg" alt="" width="600" height="800" />
  
</figure>

<p>Projekt cewki tesli wykonany na podstawie 
<a href="https://www.electroboom.com/?p=521" title="ElectroBoom">ElectroBoom</a>
oraz
<a href="https://www.youtube.com/watch?v=4OC7cwI4RNM" title="Ludic Science">Ludic Science</a></p>

<figure class="figure  figure--center">
  <img class="image" src="/pics/cewkatesli/oryginal.jpg" alt="" width="400" height="800" />
  
</figure>

<p>Najpierw wykonałem mniejszą wersję opartą na jednym tranzystorze, zasilaną baterią 9V.</p>

<figure class="figure  figure--center">
  <img class="image" src="/pics/cewkatesli/nawijanie.jpg" alt="Nawijanie cewki" width="600" height="800" />
  <figcaption class="caption">Nawijanie cewki</figcaption>
</figure>

<p>Następnie wykonałem cewkę o większych rozmiarach, w ktrórej zastosowałem 4 tranzystory oraz dodatkowy radiator, aby zapewnić odpowiednie chłodzenie. Jako źródło energii użyłem zasilacza od drukarki.</p>]]></content><author><name></name></author><category term="Elektronika" /><summary type="html"><![CDATA[Robi się groźnie.]]></summary></entry><entry><title type="html">Mapping robot</title><link href="http://localhost:4000/roboty/2015/08/25/mapping-robot/" rel="alternate" type="text/html" title="Mapping robot" /><published>2015-08-25T00:00:00+02:00</published><updated>2015-08-25T00:00:00+02:00</updated><id>http://localhost:4000/roboty/2015/08/25/mapping-robot</id><content type="html" xml:base="http://localhost:4000/roboty/2015/08/25/mapping-robot/"><![CDATA[<p>Robot that drives around and creates a map of the environment.</p>

<figure class="figure  figure--center">
  <img class="image" src="/pics/RobotMapujacy/front.jpg" alt="" width="600" height="800" />
  
</figure>

<p>This robot is the second, simplified version of the general-purpose robot. Learning from the previous design, I simplified the robot and its only task was to map rooms. Also to make the task successful I replaced the Stereovision with Kinect, as the results from it were not satisfactory. I also added encoders to the wheels, but still I made my own - incremental based on optocouplers. They didn’t work perfectly, but still allowed to achieve good results.</p>

<figure class="figure  figure--center">
  <img class="image" src="/pics/RobotMapujacy/test.jpg" alt="Prototypowanie eletkroniki" width="600" height="800" />
  <figcaption class="caption">Prototypowanie eletkroniki</figcaption>
</figure>

<p>Also, as part of this project, I realized a PID controller and set a point which the robot would reach.</p>

<p><a class="button" href="https://github.com/macstepien/MappingRobotPID" style="background: #0366d6">PID  <svg width="16" height="16" class="icon  icon--github" role="img" alt="github"><title>github</title><use xlink:href="#github" fill="CurrentColor"></use></svg>
</a></p>

<div class="embed-container">
  <iframe width="720" height="405" src="https://drive.google.com/file/d/1SI5PMQt-zXZ0vf6xvoXPK_p1-t72E7ty/preview" frameborder="0" allowfullscreen="">
  </iframe>
</div>

<p>Aby stworzyć mapę najpierw podrzebowałem odpowiednio obrobić dane. W danych głębi z Kinecta zawarte były informacje o podłodze oraz obiektach. Musiałem pozbyć się podłogi. Do osiągnięcia tego testowałem 2 metody: dopasowywanie płaszczyzny oparte na RANSACu z OpenCV oraz metodą UV-disparity, która przyspieszała obliczenia - wykrywałem linię zamiast płaszczyzny.</p>

<figure class="figure  figure--center">
  <img class="image" src="/pics/RobotMapujacy/side.jpg" alt="" width="600" height="800" />
  
</figure>

<p>Na tworzoną mapę typu Grid map nakładałem następnie wykryte obiekty. Do wyliczenia przesunięcia robota używałem wyłącznie enkoderów.</p>
<figure class="figure  figure--center">
  <img class="image" src="/pics/RobotMapujacy/map.jpg" alt="" width="500" height="800" />
  
</figure>

<p><a class="button" href="https://github.com/macstepien/MappingRobotKinect" style="background: #0366d6">Mapowanie Kinect  <svg width="16" height="16" class="icon  icon--github" role="img" alt="github"><title>github</title><use xlink:href="#github" fill="CurrentColor"></use></svg>
</a></p>

<div class="embed-container">
  <iframe width="720" height="405" src="https://drive.google.com/file/d/11cBjTDrB67s6sojRpdoVRc-anlgDSwj5/preview" frameborder="0" allowfullscreen="">
  </iframe>
</div>

<p><a class="button" href="https://github.com/macstepien/MappingRobotStereovision" style="background: #0366d6">Mapowanie Stereowizja  <svg width="16" height="16" class="icon  icon--github" role="img" alt="github"><title>github</title><use xlink:href="#github" fill="CurrentColor"></use></svg>
</a></p>

<p>Próbowałem także wykorzystać SLAMa, aby zniwelować niedoskonałości enkoderów. Jednak tutaj barierą był system operacyjny - Windows, na którym nie udało mi się uruchomić żadnej implementacji. Było to także zbyt skomplikowane zadanie jak na wiedzę, którą posiadałem, aby stworzyć własną implementację.</p>

<figure class="figure  figure--center">
  <img class="image" src="/pics/RobotMapujacy/pcb.jpg" alt="" width="600" height="800" />
  
</figure>

<p>Do sterowania robotem użyłem mikrokontrolera Atmega88Pa. Komunikował się on z komputerem poprzez interfejs UART, wykorzystałem tutaj przejściówkę na USB. Sterował on silnikami - serwami pracy ciągłej. Także mierzył napięcie z transoptorów, zliczając impulsy poprzez zastowanie odpowiedniego progu. Także dla testu wykorzystałem podczerwony czujnik odległości. Do zasilenia całej konstrukcji użyłem akumulatora żelowego. Poprzez mikrokontroler mierzyłem jego napięcie, sprawdzając czy się rozładował. Musiałem także zastosować przetwornicę Step-Up, aby zasilić Kinecta, który wymaga 12V.</p>

<p><a class="button" href="https://github.com/macstepien/MappingRobotControler" style="background: #0366d6">Sterownik Robota  <svg width="16" height="16" class="icon  icon--github" role="img" alt="github"><title>github</title><use xlink:href="#github" fill="CurrentColor"></use></svg>
</a></p>]]></content><author><name></name></author><category term="Roboty" /><summary type="html"><![CDATA[Robot that drives around and creates a map of the environment.]]></summary></entry><entry><title type="html">3D Viewer</title><link href="http://localhost:4000/oprogramowanie/2015/04/09/3dviewer/" rel="alternate" type="text/html" title="3D Viewer" /><published>2015-04-09T00:00:00+02:00</published><updated>2015-04-09T00:00:00+02:00</updated><id>http://localhost:4000/oprogramowanie/2015/04/09/3dviewer</id><content type="html" xml:base="http://localhost:4000/oprogramowanie/2015/04/09/3dviewer/"><![CDATA[<p>A piece of software for the perspective display of points in 3D.</p>

<figure class="figure  figure--center">
  <img class="image" src="/pics/3dviewer/viewer1.png" alt="" width="600" height="800" />
  
</figure>

<p>I wrote this program as part of a Computer Science lesson in High School. I implemented the loading of point clouds from a txt file. They are in the format of coordinates (X, Y, Z) and colors (R, G, B). I obtained the point clouds through stereo vision camera. It is also possible to display geometric shapes, such as a house. The whole thing was written in Pascal.</p>

<figure class="figure  figure--center">
  <img class="image" src="/pics/3dviewer/viewer2.png" alt="" width="600" height="800" />
  
</figure>

<p><a class="button" href="https://github.com/macstepien/3DViewer" style="background: #0366d6">3DViewer  <svg width="16" height="16" class="icon  icon--github" role="img" alt="github"><title>github</title><use xlink:href="#github" fill="CurrentColor"></use></svg>
</a></p>]]></content><author><name></name></author><category term="Oprogramowanie" /><summary type="html"><![CDATA[A piece of software for the perspective display of points in 3D.]]></summary></entry><entry><title type="html">General-purpose robot</title><link href="http://localhost:4000/roboty/2014/08/28/universal-robots/" rel="alternate" type="text/html" title="General-purpose robot" /><published>2014-08-28T00:00:00+02:00</published><updated>2014-08-28T00:00:00+02:00</updated><id>http://localhost:4000/roboty/2014/08/28/universal-robots</id><content type="html" xml:base="http://localhost:4000/roboty/2014/08/28/universal-robots/"><![CDATA[<p>It was supposed to make coffee…</p>

<p>This is where my imagination got carried away and I wanted to make a multipurpose robot capable of performing various activities, e.g. prepare drinks, “walk” to the store. Of course, this was intended to be the first version, on which I wanted to test my capabilities. It was to lift only dummies, and move only around the house.</p>

<figure class="figure  figure--center">
  <img class="image" src="/pics/RobotUniwersalny/robot.jpg" alt="" width="300" height="800" />
  
</figure>

<p>It was a beautiful design and very complicated. I planned to use 11 servos to operate all the limbs. This greatly exceeded the number of PWM channels in the Atmega88Pa microcontroller. That is why I was forced to use software PWM generation, which puts much more load on the processor. It was for this reason that I was forced to use a second microcontroller responsible for communicating with the computer, controlling the motors, and setting servo positions to the second microcontroller via SPI. A lot of things could have gone wrong along the way, so when I finally couldn’t control the servos I didn’t know what was going on. Only after a long time did I come to the conclusion that I must have had a power supply that was too weak, something I hadn’t even considered before. However, despite the non-functioning servos, I did not abandon the design. I still had working motors that I could control from the computer. Then I took care of an essential element of such a robot - obstacle detection and mapping. For this purpose, I wanted to use stereo vision pair. After many experiments, I finally managed to bring the stereo vision to a satisfactory level. However, there was still a lot of noise - especially on the floor. Not surprisingly, the floor, the wall, is not much detail and it’s hard to get a reliable depth image. So it was more or less successful in detecting obstacles, but when it came to motion it was a completely different matter. The webcams used returned moving images which made the detection result even worse. I did not use encoders, because I planned to detect landmarks and later calculate the displacement based on them and the resulting depth map. However, after such disappointing stereo vision results I did not try this solution anymore.</p>

<figure class="figure  figure--center">
  <img class="image" src="/pics/RobotUniwersalny/plytka.jpg" alt="" width="600" height="800" />
  
</figure>

<p>Despite the fact that it did not meet my expectations, it was an interesting construction. And my introduction to stereo vision and SLAM.</p>

<p>PR2 was my inspiration for this robot. In the final version of this robot I wanted to make it 2 times larger. The use of a rotational joint in the waist was to increase the gripping range - the ability to bend down. However, the main goal was to be able to transform, which would enable it to climb stairs and larger obstacles. By default, I wanted to use tracks.</p>

<figure class="figure  figure--center">
  <img class="image" src="/pics/RobotUniwersalny/parts.jpg" alt="" width="600" height="800" />
  
</figure>]]></content><author><name></name></author><category term="Roboty" /><summary type="html"><![CDATA[It was supposed to make coffee...]]></summary></entry></feed>