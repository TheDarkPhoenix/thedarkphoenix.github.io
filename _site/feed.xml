<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2022-11-27T15:33:49+01:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Maciej Stępień</title><subtitle>Projects</subtitle><entry><title type="html">Roomac</title><link href="http://localhost:4000/robots/2022/10/20/roomac/" rel="alternate" type="text/html" title="Roomac" /><published>2022-10-20T00:00:00+02:00</published><updated>2022-10-20T00:00:00+02:00</updated><id>http://localhost:4000/robots/2022/10/20/roomac</id><content type="html" xml:base="http://localhost:4000/robots/2022/10/20/roomac/"><![CDATA[<p>Roomac is a low-cost autonomous mobile manipulation robot. It consists of a differential drive mobile base and a 5-DoF manipulator with a gripper. The whole construction costed around 550$ and using this platform I was able to prepare a proof-of-concept application - bringing a bottle to the user. This project was described in detail in my <a href="https://raw.githubusercontent.com/macstepien/macstepien.github.io/master/files/masters_thesis_maciej_stepien.pdf">master’s thesis</a>.</p>

<div class="embed-container">
  <iframe width="720" height="405" src="https://drive.google.com/file/d/1j3mu3aWPUwXY-2VIavJLfEQMO9fqY_zH/preview" frameborder="0" allowfullscreen="">
  </iframe>
</div>

<p><a class="button" href="https://github.com/macstepien/roomac_ros" style="background: #0366d6">roomac_ros  <svg width="16" height="16" class="icon  icon--github" role="img" alt="github"><title>github</title><use xlink:href="#github" fill="CurrentColor"></use></svg>
</a></p>]]></content><author><name></name></author><category term="Robots" /><summary type="html"><![CDATA[Affordable autonomous mobile manipulation robot]]></summary></entry><entry><title type="html">Human following robot</title><link href="http://localhost:4000/robots/2019/09/24/human-following-robot/" rel="alternate" type="text/html" title="Human following robot" /><published>2019-09-24T00:00:00+02:00</published><updated>2019-09-24T00:00:00+02:00</updated><id>http://localhost:4000/robots/2019/09/24/human-following-robot</id><content type="html" xml:base="http://localhost:4000/robots/2019/09/24/human-following-robot/"><![CDATA[<p>In this tutorial I describe one way to make robot detect and follow people - it won’t make a great spy but could be useful to carry luggage or groceries. Whole system was implemented on Husarion’s ROSbot with ESP32 as a remote. To find people I used scans from LiDAR (RPLidar A2) with my detector, which is simple but turned out to be fast and quite reliable. I also checked other LiDAR approaches available on ROS - leg_detector and leg_tracker but in this case didn’t perform well enough. Another package I tested is upper_body_detector, which uses RGBD camera to detect humans. As name suggests it needs to see upper part of body - this will be a problem if we want our robot to stay close, also in this case it didn’t perform very well and was slower.</p>

<div class="embed-container">
  <iframe width="720" height="405" src="https://drive.google.com/file/d/1jNWkf1M97UBEypOCILnGTzXXnH618SYN/preview" frameborder="0" allowfullscreen="">
  </iframe>
</div>

<h2 id="setup">Setup</h2>

<h3 id="esp32-remote">ESP32 Remote</h3>

<h4 id="environment">Environment</h4>

<p>You will need to follow tutorial about <a href="https://www.hackster.io/khasreto/run-rosserial-over-the-internet-with-esp32-0615f5">setting up rosserial connection over Internet with ESP32</a>. On ROSbot prepare Husarnet connection and Rosserial for Husarnet. I recommend to set up Arduino IDE on your computer (remember to also get Rosserial for Husarnet).</p>

<h4 id="code">Code</h4>

<p>Create new sketch in Arduino IDE and copy code:<br />
<a href="https://github.com/macstepien/RosbotFollowerESPRemote/blob/master/rosbot_remote.ino">ESP Remote Code</a></p>

<p>Then get your Husarnet join code and customize code as described in <a href="https://www.hackster.io/khasreto/run-rosserial-over-the-internet-with-esp32-0615f5">ESP32 Husarnet Tutorial</a></p>

<h4 id="wiring">Wiring</h4>

<p>Wire your ESP32 accordingly to schematics:</p>

<figure class="figure  figure--center">
  <img class="image" src="/pics/RosbotFollower/remoteSchematics.png" alt="" width="600" height="800" />
  
</figure>

<p>As a source of power you can use a Powerbank connected to the ESP.</p>

<h3 id="rosbot">ROSbot</h3>

<p>This project is meant to run on CORE2 with Mbed firmware. So be sure that you updated your firmware as described in <a href="https://husarion.com/tutorials/howtostart/rosbot---quick-start/">ROSbot quick start</a>. On ROSbot you will need to install following dependencies:</p>

<ul>
  <li><strong>scikit-learn</strong> python library (for clusterization)
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>apt-get <span class="nb">install </span>python-scikits-learn
</code></pre></div>    </div>
  </li>
  <li>
    <p><strong>pykalman</strong><br />
Follow installation tutorial on <a href="https://pykalman.github.io/">pykalman page</a></p>
  </li>
  <li><strong>rosbot_description</strong> package (for URDF visualization model and bridge node)<br />
Go to your ROS workspace and clone repository:
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cd</span> ~/ros_workspace/src
git clone https://github.com/husarion/rosbot_description.git
</code></pre></div>    </div>
    <p>Install dependencies:</p>
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cd</span> ~/ros_workspace
rosdep <span class="nb">install</span> <span class="nt">--from-paths</span> src <span class="nt">--ignore-src</span> <span class="nt">-r</span> <span class="nt">-y</span>
</code></pre></div>    </div>
  </li>
  <li><strong>rosbot_ekf</strong><br />
Install dependency:
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>apt-get <span class="nb">install </span>ros-kinetic-robot-localization
</code></pre></div>    </div>
    <p>Get package:</p>
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git clone https://github.com/byq77/rosbot_ekf.git
</code></pre></div>    </div>
  </li>
</ul>

<p>Then go back to src folder in your workspace:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cd</span> ~/ros_workspace/src
</code></pre></div></div>

<p>Download code:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git clone https://github.com/macstepien/rosbot_follower.git
</code></pre></div></div>

<p>And finally build your workspace:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cd</span> ~/ros_workspace
catkin_make
</code></pre></div></div>

<h2 id="usage">Usage</h2>

<p>There are two options available:</p>

<ul>
  <li>followerSlow - better if you have little space and walk slowly.<br />
To run it you only need to copy this commande into new terminal window:
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>roslaunch rosbot_follower followerSlow.launch
</code></pre></div>    </div>
  </li>
  <li>followerKalman - this one should be able to follow you with normal walking, but it also needs some space to gain speed.<br />
Roslaunch command:
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>roslaunch rosbot_follower followerKalman.launch
</code></pre></div>    </div>
  </li>
</ul>

<p>After whole system is up and running stand in front of ROSbot, but not too far away. When you are detected blue LED on ESP should turn on. Then you can press first button (the one closer to ESP on schematics) and if you start walking robot should follow you. When LED turns off it means that algorithm lost detection of you and need to recalibrate (stand closer to robot and wait until blue LED is back on). If robot had false detection you can calibrate again by pressing second button. On RViz you can see visualization: scan from LiDAR, robot model and detections. Green spheres are all potential legs, blue cylinders are detected legs and red tall cylinder is human position. In version with Kalman filter we also publish circle around human, which shows how much estimated position differs from measurement.</p>

<figure class="figure  figure--center">
  <img class="image" src="/pics/RosbotFollower/rviz.png" alt="" width="600" height="800" />
  
</figure>

<h3 id="troubleshooting">Troubleshooting</h3>

<ul>
  <li><strong>LED doesn’t turn on</strong> - check RViz if you can see detected human (red cylinder). If there is a detection then press Dead Man’s Button and try to walk.</li>
  <li><strong>ROSbot doesn’t respond</strong> - you should check your connection to ESP32. You can do so by echoing button topic:
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>rostopic <span class="nb">echo</span> /esp_remote/start
</code></pre></div>    </div>
    <p>If nothing can be seen, try restarting your ESP by turning it off and on again.</p>
  </li>
</ul>

<h2 id="algorithm-walkthrough">Algorithm walkthrough</h2>

<p>First we will go through slower version, as it is simpler. Main part of this code is scan callback where all the magic happens - data from LiDAR is analyzed and people are detected. Whole process consists of 5 steps:</p>

<ol>
  <li>Clusterization</li>
  <li>Leg detection</li>
  <li>Human detection</li>
  <li>Marker publishing</li>
  <li>Control</li>
</ol>

<h3 id="1-clusterization">1. Clusterization</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">scanCallback</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scan</span><span class="p">):</span>
    <span class="n">clusterList</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">findClusters</span><span class="p">(</span><span class="n">scan</span><span class="p">)</span>
    <span class="p">...</span>
</code></pre></div></div>

<p>First we find clusters in our scan using Euclidean Clusterization Algorithm:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">findClusters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scan</span><span class="p">):</span>
    <span class="n">pointsList</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
    <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">scan</span><span class="p">.</span><span class="n">ranges</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">r</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="p">.</span><span class="n">minRange</span> <span class="ow">and</span> <span class="n">r</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="p">.</span><span class="n">maxRange</span><span class="p">:</span>
            <span class="n">alfa</span> <span class="o">=</span> <span class="n">scan</span><span class="p">.</span><span class="n">angle_min</span> <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="n">scan</span><span class="p">.</span><span class="n">angle_increment</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">r</span> <span class="o">*</span> <span class="n">math</span><span class="p">.</span><span class="n">cos</span><span class="p">(</span><span class="n">alfa</span><span class="p">)</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">r</span> <span class="o">*</span> <span class="n">math</span><span class="p">.</span><span class="n">sin</span><span class="p">(</span><span class="n">alfa</span><span class="p">)</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">alfa</span> <span class="o">&gt;</span> <span class="o">-</span><span class="n">math</span><span class="p">.</span><span class="n">pi</span> <span class="ow">and</span> <span class="n">alfa</span> <span class="o">&lt;</span> <span class="o">-</span><span class="bp">self</span><span class="p">.</span><span class="n">maxAngle</span><span class="p">)</span> <span class="ow">or</span> \
                <span class="p">(</span><span class="n">alfa</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="p">.</span><span class="n">maxAngle</span> <span class="ow">and</span> <span class="n">alfa</span> <span class="o">&lt;</span> <span class="n">math</span><span class="p">.</span><span class="n">pi</span><span class="p">):</span>
                <span class="n">pointsList</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">pointsList</span><span class="p">,</span> <span class="p">[[</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">]],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">r</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="p">.</span><span class="n">minRange</span><span class="p">:</span>
            <span class="n">rospy</span><span class="p">.</span><span class="n">logerr</span><span class="p">(</span><span class="s">"Obstacle detected"</span><span class="p">)</span>
            <span class="k">return</span> <span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))]</span>
        <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">db</span> <span class="o">=</span> <span class="n">DBSCAN</span><span class="p">(</span><span class="n">eps</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">clusterizationMaxDistanceParam</span><span class="p">,</span>
                <span class="n">min_samples</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">clusterizationMinSamplesParam</span><span class="p">).</span><span class="n">fit</span><span class="p">(</span><span class="n">pointsList</span><span class="p">)</span>
    <span class="n">core_samples_mask</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">db</span><span class="p">.</span><span class="n">labels_</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
    <span class="n">core_samples_mask</span><span class="p">[</span><span class="n">db</span><span class="p">.</span><span class="n">core_sample_indices_</span><span class="p">]</span> <span class="o">=</span> <span class="bp">True</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">db</span><span class="p">.</span><span class="n">labels_</span>
    <span class="n">n_clusters_</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">labels</span><span class="p">))</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span> <span class="k">if</span> <span class="o">-</span><span class="mi">1</span> <span class="ow">in</span> <span class="n">labels</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">unique_labels</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
    <span class="n">clusterList</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">unique_labels</span><span class="p">:</span>
        <span class="n">class_member_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">labels</span> <span class="o">==</span> <span class="n">k</span><span class="p">)</span>
        <span class="n">xy</span> <span class="o">=</span> <span class="n">pointsList</span><span class="p">[</span><span class="n">class_member_mask</span> <span class="o">&amp;</span> <span class="n">core_samples_mask</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">xy</span><span class="p">.</span><span class="nb">any</span><span class="p">():</span>
            <span class="n">clusterList</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">xy</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">clusterList</span>
</code></pre></div></div>

<p>Here we have few parameters that you can customize:</p>

<ul>
  <li><strong>minRange</strong> - used to filter ranges from lidar points, if anything gets closer than that, then ROSbot treats it as obstacle and stops</li>
  <li><strong>maxRange</strong> - data from lidar further than that value are dismissed</li>
  <li><strong>maxAngle</strong> - readings have to be in front of ROSbot in ranges (maxAngle, Pi) u (-Pi, -maxAngle)</li>
  <li><strong>clusterizationMaxDistanceParam</strong> - maximum distance between points to add new point to cluster</li>
  <li><strong>clusterizationMinSamplesParam</strong> - minimum number of points in cluster</li>
</ul>

<p>More information about <a href="https://scikit-learn.org/stable/modules/clustering.html#dbscan">DBSCAN clusterization</a></p>

<p>Back to scanCallback:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">scanCallback</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scan</span><span class="p">):</span>
    <span class="p">...</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">clusterList</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    	<span class="n">rospy</span><span class="p">.</span><span class="n">logwarn</span><span class="p">(</span><span class="s">"No clusters detected"</span><span class="p">)</span>
    	<span class="k">if</span> <span class="n">rospy</span><span class="p">.</span><span class="n">get_time</span><span class="p">()</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">lastDetectionTime</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="p">.</span><span class="n">detectionTimeout</span><span class="p">:</span>
            <span class="n">humanPosition</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">lastHumanPosition</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">controlRosbot</span><span class="p">(</span><span class="n">humanPosition</span><span class="p">)</span>
    	<span class="k">else</span><span class="p">:</span>
            <span class="n">led</span> <span class="o">=</span> <span class="n">Bool</span><span class="p">()</span>
            <span class="n">led</span><span class="p">.</span><span class="n">data</span> <span class="o">=</span> <span class="bp">False</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">ledPub</span><span class="p">.</span><span class="n">publish</span><span class="p">(</span><span class="n">led</span><span class="p">)</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">positionCalibration</span> <span class="o">=</span> <span class="bp">True</span>
            <span class="n">rosbotControl</span> <span class="o">=</span> <span class="n">Twist</span><span class="p">()</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">speedPub</span><span class="p">.</span><span class="n">publish</span><span class="p">(</span><span class="n">rosbotControl</span><span class="p">)</span>
    	<span class="k">return</span>
    <span class="k">elif</span> <span class="p">(</span><span class="n">clusterList</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">clusterList</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
    	<span class="n">led</span> <span class="o">=</span> <span class="n">Bool</span><span class="p">()</span>
    	<span class="n">led</span><span class="p">.</span><span class="n">data</span> <span class="o">=</span> <span class="bp">False</span>
    	<span class="bp">self</span><span class="p">.</span><span class="n">ledPub</span><span class="p">.</span><span class="n">publish</span><span class="p">(</span><span class="n">led</span><span class="p">)</span>
    	<span class="bp">self</span><span class="p">.</span><span class="n">positionCalibration</span> <span class="o">=</span> <span class="bp">True</span>
    	<span class="n">rosbotControl</span> <span class="o">=</span> <span class="n">Twist</span><span class="p">()</span>
    	<span class="bp">self</span><span class="p">.</span><span class="n">speedPub</span><span class="p">.</span><span class="n">publish</span><span class="p">(</span><span class="n">rosbotControl</span><span class="p">)</span>
    	<span class="k">return</span>
    <span class="p">...</span>
</code></pre></div></div>

<p>In here we check results of clusterization. If we didn’t detect anything, we continue movement in last seen human position. That is until our last seen position is too old - then we need to stop and assume we lost track of our human, which we signal through LED.<br />
We pass special value when obstacle is detected - in first cluster first point is set to (0,0). In this case robot needs to stop immediately, as obstacle is too close.</p>

<ul>
  <li><strong>detectionTimeout</strong> - how much time (in seconds) we can trust last seen position and follow it</li>
</ul>

<h3 id="2-leg-detection">2. Leg detection</h3>

<p>Next step is leg detection:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">scanCallback</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scan</span><span class="p">):</span>
    <span class="p">...</span>
    <span class="n">sortedClusters</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">detectLegs</span><span class="p">(</span><span class="n">clusterList</span><span class="p">)</span>
    <span class="p">...</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">detectLegs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">clusterList</span><span class="p">):</span>
    <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">sortedClusters</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">cluster</span> <span class="ow">in</span> <span class="n">clusterList</span><span class="p">:</span>
    	<span class="n">xMax</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="n">cluster</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span>
    	<span class="n">xMin</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">min</span><span class="p">(</span><span class="n">cluster</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span>
    	<span class="n">yMax</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="n">cluster</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
    	<span class="n">yMin</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">min</span><span class="p">(</span><span class="n">cluster</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
    	<span class="n">xDistance</span> <span class="o">=</span> <span class="n">xMax</span> <span class="o">-</span> <span class="n">xMin</span>
    	<span class="n">yDistance</span> <span class="o">=</span> <span class="n">yMax</span> <span class="o">-</span> <span class="n">yMin</span>
    	<span class="n">proportion</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">xDistance</span><span class="p">,</span><span class="n">yDistance</span><span class="p">)</span><span class="o">/</span><span class="nb">min</span><span class="p">(</span><span class="n">xDistance</span><span class="p">,</span> <span class="n">yDistance</span><span class="p">)</span>
    	<span class="n">area</span> <span class="o">=</span> <span class="n">xDistance</span><span class="o">*</span><span class="n">yDistance</span>
    	<span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">xDistance</span><span class="p">,</span><span class="n">yDistance</span><span class="p">)</span><span class="o">-</span><span class="bp">self</span><span class="p">.</span><span class="n">legWidth</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="p">.</span><span class="n">dLegWidth</span><span class="p">:</span>
    		<span class="k">continue</span>
    	<span class="n">xMean</span> <span class="o">=</span> <span class="p">(</span><span class="n">xMax</span><span class="o">+</span><span class="n">xMin</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span>
    	<span class="n">yMean</span> <span class="o">=</span> <span class="p">(</span><span class="n">yMax</span><span class="o">+</span><span class="n">yMin</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span>
    	<span class="n">cone</span> <span class="o">=</span> <span class="n">Point</span><span class="p">()</span>
    	<span class="n">cone</span><span class="p">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">xMean</span>
    	<span class="n">cone</span><span class="p">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">yMean</span>
    	<span class="n">cone</span><span class="p">.</span><span class="n">z</span> <span class="o">=</span> <span class="mi">0</span>
    	<span class="n">sortedClusters</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">cone</span><span class="p">)</span>
    <span class="n">sortedClusters</span><span class="p">.</span><span class="n">sort</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">math</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">x</span><span class="p">.</span><span class="n">y</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">sortedClusters</span>
</code></pre></div></div>

<p>In this section we go through each cluster and calculate its bounding rectangle. Then we filter our data with following rule: longer side of rectangle can have maximal length of legWidth + dLegWidth (meaning that we assume leg width of legWidth with upper toleration dLegWidth). I encourage you to experiment with it and maybe try other conditions e.g. area and sides proportions. If cluster passes we find its centroid and save it for further calculations. As last thing we sort our potential legs by distance from ROSbot.</p>

<ul>
  <li><strong>legWidth</strong> - width of the leg</li>
  <li><strong>dLegWidth</strong> - toleration of leg width</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">scanCallback</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scan</span><span class="p">):</span>
    <span class="p">...</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">sortedClusters</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    	<span class="n">rospy</span><span class="p">.</span><span class="n">logwarn</span><span class="p">(</span><span class="s">"No legs detected"</span><span class="p">)</span>
    	<span class="k">if</span> <span class="n">rospy</span><span class="p">.</span><span class="n">get_time</span><span class="p">()</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">lastDetectionTime</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="p">.</span><span class="n">detectionTimeout</span><span class="p">:</span>
            <span class="n">humanPosition</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">lastHumanPosition</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">controlRosbot</span><span class="p">(</span><span class="n">humanPosition</span><span class="p">)</span>
    	<span class="k">else</span><span class="p">:</span>
            <span class="n">led</span> <span class="o">=</span> <span class="n">Bool</span><span class="p">()</span>
            <span class="n">led</span><span class="p">.</span><span class="n">data</span> <span class="o">=</span> <span class="bp">False</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">ledPub</span><span class="p">.</span><span class="n">publish</span><span class="p">(</span><span class="n">led</span><span class="p">)</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">positionCalibration</span> <span class="o">=</span> <span class="bp">True</span>
            <span class="n">rosbotControl</span> <span class="o">=</span> <span class="n">Twist</span><span class="p">()</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">speedPub</span><span class="p">.</span><span class="n">publish</span><span class="p">(</span><span class="n">rosbotControl</span><span class="p">)</span>
    	<span class="k">return</span>
    <span class="p">...</span>
</code></pre></div></div>

<p>Similar to previous step we check results of leg detection. No legs found - we allow ROSbot to move for some time. This step is necessary to smooth out movement - sometimes in only one frame we don’t detect any legs, which can cause robot to stop and go.</p>

<h3 id="3-human-detection">3. Human detection</h3>

<p>We estimate human position through analysis of legs detections:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">scanCallback</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scan</span><span class="p">):</span>
    <span class="p">...</span>
    <span class="p">(</span><span class="n">firstLeg</span><span class="p">,</span> <span class="n">secondLeg</span><span class="p">,</span> <span class="n">humanPosition</span><span class="p">,</span> <span class="n">firstLegDetected</span><span class="p">,</span> <span class="n">twoLegsDetected</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">detectHuman</span><span class="p">(</span><span class="n">sortedClusters</span><span class="p">)</span>
    <span class="p">...</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">detectHuman</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sortedClusters</span><span class="p">):</span>
    <span class="n">firstLeg</span> <span class="o">=</span> <span class="n">sortedClusters</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">firstLegDetected</span> <span class="o">=</span> <span class="bp">False</span>
    <span class="n">twoLegsDetected</span> <span class="o">=</span> <span class="bp">False</span>
    <span class="n">secondLeg</span> <span class="o">=</span> <span class="n">Point</span><span class="p">()</span>
    <span class="n">humanPosition</span> <span class="o">=</span> <span class="n">Point</span><span class="p">()</span>
    <span class="n">humanPositionTemp</span> <span class="o">=</span> <span class="n">Point</span><span class="p">()</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">sortedClusters</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
    	<span class="n">sortedClusters</span><span class="p">.</span><span class="n">sort</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">math</span><span class="p">.</span><span class="n">sqrt</span><span class="p">((</span><span class="n">x</span><span class="p">.</span><span class="n">x</span><span class="o">-</span><span class="n">firstLeg</span><span class="p">.</span><span class="n">x</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">y</span><span class="o">-</span><span class="n">firstLeg</span><span class="p">.</span><span class="n">y</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>
    	<span class="n">secondLeg</span> <span class="o">=</span> <span class="n">sortedClusters</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    	<span class="n">legDistance</span> <span class="o">=</span> <span class="n">math</span><span class="p">.</span><span class="n">sqrt</span><span class="p">((</span><span class="n">firstLeg</span><span class="p">.</span><span class="n">x</span> <span class="o">-</span> <span class="n">secondLeg</span><span class="p">.</span><span class="n">x</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="p">(</span><span class="n">firstLeg</span><span class="p">.</span><span class="n">y</span> <span class="o">-</span> <span class="n">secondLeg</span><span class="p">.</span><span class="n">y</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    	<span class="k">if</span> <span class="n">legDistance</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="p">.</span><span class="n">legDistanceThreshold</span><span class="p">:</span>
            <span class="n">humanPositionTemp</span><span class="p">.</span><span class="n">x</span> <span class="o">=</span> <span class="p">(</span><span class="n">firstLeg</span><span class="p">.</span><span class="n">x</span><span class="o">+</span><span class="n">secondLeg</span><span class="p">.</span><span class="n">x</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span>
            <span class="n">humanPositionTemp</span><span class="p">.</span><span class="n">y</span> <span class="o">=</span> <span class="p">(</span><span class="n">firstLeg</span><span class="p">.</span><span class="n">y</span><span class="o">+</span><span class="n">secondLeg</span><span class="p">.</span><span class="n">y</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span>
            <span class="n">humanPositionTemp</span><span class="p">.</span><span class="n">z</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">twoLegsDetected</span> <span class="o">=</span> <span class="bp">True</span>
    	<span class="k">else</span><span class="p">:</span>
            <span class="n">humanPositionTemp</span> <span class="o">=</span> <span class="n">firstLeg</span>
    <span class="k">else</span><span class="p">:</span>
    	<span class="n">humanPositionTemp</span> <span class="o">=</span> <span class="n">firstLeg</span>
    <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">positionCalibration</span><span class="p">:</span>
    	<span class="n">r</span> <span class="o">=</span> <span class="n">math</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span> <span class="n">humanPositionTemp</span><span class="p">.</span><span class="n">x</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">+</span> <span class="n">humanPositionTemp</span><span class="p">.</span><span class="n">y</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
    	<span class="k">if</span> <span class="n">r</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="p">.</span><span class="n">calibrationDistance</span> <span class="ow">and</span> <span class="n">twoLegsDetected</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">lastHumanPosition</span> <span class="o">=</span> <span class="n">humanPositionTemp</span>
            <span class="n">humanPosition</span> <span class="o">=</span> <span class="n">humanPositionTemp</span>
            <span class="n">firstLegDetected</span> <span class="o">=</span> <span class="bp">True</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">lastDetectionTime</span> <span class="o">=</span> <span class="n">rospy</span><span class="p">.</span><span class="n">get_time</span><span class="p">()</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">positionCalibration</span> <span class="o">=</span> <span class="bp">False</span>
            <span class="n">led</span> <span class="o">=</span> <span class="n">Bool</span><span class="p">()</span>
            <span class="n">led</span><span class="p">.</span><span class="n">data</span> <span class="o">=</span> <span class="bp">True</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">ledPub</span><span class="p">.</span><span class="n">publish</span><span class="p">(</span><span class="n">led</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
    	<span class="n">distanceChange</span> <span class="o">=</span> <span class="n">math</span><span class="p">.</span><span class="n">sqrt</span><span class="p">((</span><span class="bp">self</span><span class="p">.</span><span class="n">lastHumanPosition</span><span class="p">.</span><span class="n">x</span> <span class="o">-</span> <span class="n">humanPositionTemp</span><span class="p">.</span><span class="n">x</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> \
    				<span class="o">+</span> <span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">lastHumanPosition</span><span class="p">.</span><span class="n">y</span> <span class="o">-</span> <span class="n">humanPositionTemp</span><span class="p">.</span><span class="n">y</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    	<span class="k">if</span> <span class="n">distanceChange</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="p">.</span><span class="n">humanPositionChangeThreshold</span><span class="p">:</span>
            <span class="n">humanPosition</span> <span class="o">=</span> <span class="n">humanPositionTemp</span>
            <span class="n">firstLegDetected</span> <span class="o">=</span> <span class="bp">True</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">lastHumanPosition</span> <span class="o">=</span> <span class="n">humanPosition</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">lastDetectionTime</span> <span class="o">=</span> <span class="n">rospy</span><span class="p">.</span><span class="n">get_time</span><span class="p">()</span>
    	<span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">rospy</span><span class="p">.</span><span class="n">get_time</span><span class="p">()</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">lastDetectionTime</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="p">.</span><span class="n">detectionTimeout</span><span class="p">:</span>
                <span class="n">humanPosition</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">lastHumanPosition</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">led</span> <span class="o">=</span> <span class="n">Bool</span><span class="p">()</span>
                <span class="n">led</span><span class="p">.</span><span class="n">data</span> <span class="o">=</span> <span class="bp">False</span>
                <span class="bp">self</span><span class="p">.</span><span class="n">ledPub</span><span class="p">.</span><span class="n">publish</span><span class="p">(</span><span class="n">led</span><span class="p">)</span>
                <span class="bp">self</span><span class="p">.</span><span class="n">positionCalibration</span> <span class="o">=</span> <span class="bp">True</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">firstLeg</span><span class="p">,</span> <span class="n">secondLeg</span><span class="p">,</span> <span class="n">humanPosition</span><span class="p">,</span> <span class="n">firstLegDetected</span><span class="p">,</span> <span class="n">twoLegsDetected</span><span class="p">)</span>
</code></pre></div></div>

<p>We assume our first detected leg is one closest to ROSbot. Second leg (if any available) is one closest to first leg (if it’s close enough). With two legs detected we calculate possible human position as mean between legs, otherwise we use first leg as possible human position.<br />
When human position is not calibrated, then two legs have to be visible in range closer than given threshold. Provided that our position is already calibrated, we can check if our detected human position is viable. We calculate difference in positions between new and old detection, too big value means that it’s probably false detection. In this case we check if we can use older position, otherwise we lost track of human position.</p>

<ul>
  <li><strong>legDistanceThreshold</strong> - maximum distance from first leg to second leg, if second leg distance is more than that, we use only first leg detection</li>
  <li><strong>calibrationDistance</strong> - maximum distance from human to ROSbot to initialize position</li>
  <li><strong>humanPositionChangeThreshold</strong> - maximum distance between last detected human position and recent human position</li>
  <li><strong>detectionTimeout</strong> - how much time we can use old detection as human position, if we exceed this time we consider that we lost our human detection</li>
</ul>

<h3 id="4-marker-publishing">4. Marker publishing</h3>

<p>Visualization of our detections</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">scanCallback</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scan</span><span class="p">):</span>
    <span class="p">...</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">publishMarkers</span><span class="p">(</span><span class="n">firstLeg</span><span class="p">,</span> <span class="n">secondLeg</span><span class="p">,</span> <span class="n">humanPosition</span><span class="p">,</span> <span class="n">firstLegDetected</span><span class="p">,</span> <span class="n">twoLegsDetected</span><span class="p">,</span> <span class="n">sortedClusters</span><span class="p">)</span>
    <span class="p">...</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">publishMarkers</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">firstLeg</span><span class="p">,</span> <span class="n">secondLeg</span><span class="p">,</span> <span class="n">humanPosition</span><span class="p">,</span> <span class="n">firstLegDetected</span><span class="p">,</span> <span class="n">twoLegsDetected</span><span class="p">,</span> <span class="n">sortedClusters</span><span class="p">):</span>
    <span class="n">legMarker</span> <span class="o">=</span> <span class="n">Marker</span><span class="p">()</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">header</span><span class="p">.</span><span class="n">frame_id</span> <span class="o">=</span> <span class="s">"laser"</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">ns</span> <span class="o">=</span> <span class="s">"person"</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">header</span><span class="p">.</span><span class="n">stamp</span> <span class="o">=</span> <span class="n">rospy</span><span class="p">.</span><span class="n">Time</span><span class="p">()</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="nb">type</span> <span class="o">=</span> <span class="n">Marker</span><span class="p">.</span><span class="n">CYLINDER</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">action</span> <span class="o">=</span> <span class="n">Marker</span><span class="p">.</span><span class="n">ADD</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">pose</span><span class="p">.</span><span class="n">orientation</span><span class="p">.</span><span class="n">x</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">pose</span><span class="p">.</span><span class="n">orientation</span><span class="p">.</span><span class="n">y</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">pose</span><span class="p">.</span><span class="n">orientation</span><span class="p">.</span><span class="n">z</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">pose</span><span class="p">.</span><span class="n">orientation</span><span class="p">.</span><span class="n">w</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">scale</span><span class="p">.</span><span class="n">x</span> <span class="o">=</span> <span class="mf">0.04</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">scale</span><span class="p">.</span><span class="n">y</span> <span class="o">=</span> <span class="mf">0.04</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">scale</span><span class="p">.</span><span class="n">z</span> <span class="o">=</span> <span class="mf">0.04</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">color</span><span class="p">.</span><span class="n">a</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">color</span><span class="p">.</span><span class="n">r</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">color</span><span class="p">.</span><span class="n">g</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">color</span><span class="p">.</span><span class="n">b</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">lifetime</span> <span class="o">=</span> <span class="n">rospy</span><span class="p">.</span><span class="n">Duration</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="p">.</span><span class="n">positionCalibration</span><span class="p">:</span>
    	<span class="c1">#first leg
</span>        <span class="k">if</span> <span class="n">firstLegDetected</span><span class="p">:</span>
            <span class="n">legMarker</span><span class="p">.</span><span class="nb">id</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="n">legMarker</span><span class="p">.</span><span class="n">pose</span><span class="p">.</span><span class="n">position</span> <span class="o">=</span> <span class="n">firstLeg</span>
            <span class="n">legMarker</span><span class="p">.</span><span class="n">pose</span><span class="p">.</span><span class="n">position</span><span class="p">.</span><span class="n">z</span> <span class="o">=</span> <span class="mf">0.02</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">legPub</span><span class="p">.</span><span class="n">publish</span><span class="p">(</span><span class="n">legMarker</span><span class="p">)</span>
        <span class="c1">#second leg
</span>        <span class="k">if</span> <span class="n">twoLegsDetected</span><span class="p">:</span>
            <span class="n">legMarker</span><span class="p">.</span><span class="nb">id</span> <span class="o">=</span> <span class="mi">2</span>
            <span class="n">legMarker</span><span class="p">.</span><span class="n">pose</span><span class="p">.</span><span class="n">position</span> <span class="o">=</span> <span class="n">secondLeg</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">legPub</span><span class="p">.</span><span class="n">publish</span><span class="p">(</span><span class="n">legMarker</span><span class="p">)</span>
    	<span class="c1">#human position
</span>    	<span class="n">legMarker</span><span class="p">.</span><span class="nb">id</span> <span class="o">=</span> <span class="mi">3</span>
    	<span class="n">legMarker</span><span class="p">.</span><span class="n">scale</span><span class="p">.</span><span class="n">z</span> <span class="o">=</span> <span class="mf">0.2</span>
    	<span class="n">legMarker</span><span class="p">.</span><span class="n">pose</span><span class="p">.</span><span class="n">position</span> <span class="o">=</span> <span class="n">humanPosition</span>
    	<span class="n">legMarker</span><span class="p">.</span><span class="n">pose</span><span class="p">.</span><span class="n">position</span><span class="p">.</span><span class="n">z</span> <span class="o">=</span> <span class="mf">0.1</span>
    	<span class="n">legMarker</span><span class="p">.</span><span class="n">color</span><span class="p">.</span><span class="n">r</span> <span class="o">=</span> <span class="mf">1.0</span>
    	<span class="n">legMarker</span><span class="p">.</span><span class="n">color</span><span class="p">.</span><span class="n">b</span> <span class="o">=</span> <span class="mf">0.0</span>
    	<span class="bp">self</span><span class="p">.</span><span class="n">legPub</span><span class="p">.</span><span class="n">publish</span><span class="p">(</span><span class="n">legMarker</span><span class="p">)</span>
    <span class="n">legMarker</span> <span class="o">=</span> <span class="n">Marker</span><span class="p">()</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">ns</span> <span class="o">=</span> <span class="s">"legs"</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">header</span><span class="p">.</span><span class="n">frame_id</span> <span class="o">=</span> <span class="s">"laser"</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">header</span><span class="p">.</span><span class="n">stamp</span> <span class="o">=</span> <span class="n">rospy</span><span class="p">.</span><span class="n">Time</span><span class="p">()</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="nb">type</span> <span class="o">=</span> <span class="n">Marker</span><span class="p">.</span><span class="n">SPHERE</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">action</span> <span class="o">=</span> <span class="n">Marker</span><span class="p">.</span><span class="n">ADD</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">pose</span><span class="p">.</span><span class="n">orientation</span><span class="p">.</span><span class="n">x</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">pose</span><span class="p">.</span><span class="n">orientation</span><span class="p">.</span><span class="n">y</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">pose</span><span class="p">.</span><span class="n">orientation</span><span class="p">.</span><span class="n">z</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">pose</span><span class="p">.</span><span class="n">orientation</span><span class="p">.</span><span class="n">w</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">scale</span><span class="p">.</span><span class="n">x</span> <span class="o">=</span> <span class="mf">0.04</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">scale</span><span class="p">.</span><span class="n">y</span> <span class="o">=</span> <span class="mf">0.04</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">scale</span><span class="p">.</span><span class="n">z</span> <span class="o">=</span> <span class="mf">0.04</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">color</span><span class="p">.</span><span class="n">a</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">color</span><span class="p">.</span><span class="n">r</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">color</span><span class="p">.</span><span class="n">g</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">color</span><span class="p">.</span><span class="n">b</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">legMarker</span><span class="p">.</span><span class="n">lifetime</span> <span class="o">=</span> <span class="n">rospy</span><span class="p">.</span><span class="n">Duration</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)</span>
    <span class="n">i</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">sortedClusters</span><span class="p">:</span>
    	<span class="n">legMarker</span><span class="p">.</span><span class="nb">id</span> <span class="o">=</span> <span class="n">i</span>
    	<span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
    	<span class="n">legMarker</span><span class="p">.</span><span class="n">pose</span><span class="p">.</span><span class="n">position</span><span class="p">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">x</span>
    	<span class="n">legMarker</span><span class="p">.</span><span class="n">pose</span><span class="p">.</span><span class="n">position</span><span class="p">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">y</span>
    	<span class="bp">self</span><span class="p">.</span><span class="n">legPub</span><span class="p">.</span><span class="n">publish</span><span class="p">(</span><span class="n">legMarker</span><span class="p">)</span>
</code></pre></div></div>

<p>Pretty straightforward: we publish markers with potential legs (green spheres), detected legs (if any found, blue cylinders) and human (red cylinder).</p>

<h3 id="5-control">5. Control</h3>

<p>And final step is movement control:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">scanCallback</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scan</span><span class="p">):</span>
    <span class="p">...</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">controlRosbot</span><span class="p">(</span><span class="n">humanPosition</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">controlRosbot</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">humanPosition</span><span class="p">):</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">math</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span> <span class="n">humanPosition</span><span class="p">.</span><span class="n">x</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">+</span> <span class="n">humanPosition</span><span class="p">.</span><span class="n">y</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">math</span><span class="p">.</span><span class="n">atan2</span><span class="p">(</span><span class="n">humanPosition</span><span class="p">.</span><span class="n">y</span><span class="p">,</span> <span class="o">-</span><span class="n">humanPosition</span><span class="p">.</span><span class="n">x</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">r</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="p">.</span><span class="n">minHumanDistance</span><span class="p">:</span>
    	<span class="n">xSpeed</span> <span class="o">=</span> <span class="o">-</span><span class="n">r</span> <span class="o">*</span> <span class="bp">self</span><span class="p">.</span><span class="n">speedPGain</span>
    <span class="k">else</span><span class="p">:</span>
    	<span class="n">xSpeed</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="p">.</span><span class="n">minHumanAngle</span><span class="p">:</span>
    	<span class="n">zAngularSpeed</span> <span class="o">=</span> <span class="n">a</span> <span class="o">*</span> <span class="bp">self</span><span class="p">.</span><span class="n">angularSpeedPGain</span>
    <span class="k">else</span><span class="p">:</span>
    	<span class="n">zAngularSpeed</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">rosbotControl</span> <span class="o">=</span> <span class="n">Twist</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">rospy</span><span class="p">.</span><span class="n">get_time</span><span class="p">()</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">buttonTime</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="p">.</span><span class="n">buttonTimeout</span> <span class="ow">and</span> \
    		<span class="bp">self</span><span class="p">.</span><span class="n">buttonState</span> <span class="o">==</span> <span class="bp">True</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="p">.</span><span class="n">positionCalibration</span><span class="p">:</span>
    	<span class="n">rosbotControl</span><span class="p">.</span><span class="n">linear</span><span class="p">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">xSpeed</span>
    	<span class="n">rosbotControl</span><span class="p">.</span><span class="n">angular</span><span class="p">.</span><span class="n">z</span> <span class="o">=</span> <span class="n">zAngularSpeed</span>
    	<span class="bp">self</span><span class="p">.</span><span class="n">speedPub</span><span class="p">.</span><span class="n">publish</span><span class="p">(</span><span class="n">rosbotControl</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
    	<span class="bp">self</span><span class="p">.</span><span class="n">speedPub</span><span class="p">.</span><span class="n">publish</span><span class="p">(</span><span class="n">rosbotControl</span><span class="p">)</span>
</code></pre></div></div>

<p>Firstly we convert our cartesian coordinates to polar ones. Then we calculate angular and linear speed for ROSbot with proportional controller. We publish it if we receive message from remote that allow robot to move.</p>

<ul>
  <li><strong>minHumanDistance</strong> - if human distance is more than that robot will start following</li>
  <li><strong>minHumanAngle</strong> - if human angle is more than that robot will start following</li>
  <li><strong>speedPGain</strong> - proportional gain for linear ROSbot speed (increase if you want your robot to go faster)</li>
  <li><strong>angularSpeedPGain</strong> - proportional gain for angular ROSbot speed (increase if you want your robot to turn faster)</li>
  <li><strong>buttonTimeout</strong> (seconds) - if we don’t receive new Dead Man’s Button message for that time ROSbot isn’t allowed to move</li>
</ul>

<h3 id="followerkalman">FollowerKalman</h3>

<p>This version is improved slow follower - basically only additions are scoring system and Kalman filter. Also I changed some parameters to make it more suitable for higher speeds.<br />
In order to implement Kalman filter I created Person class where human position is stored and updated. For Kalman Filter part I used code from <a href="https://github.com/angusleigh/leg_tracker">leg_tracker</a>. All the parameters for filter were well tuned, I only changed std_obs value.</p>

<ul>
  <li><strong>std_obs</strong> - increasing this value means you don’t trust your measurements and as the effect your data is much more filtered. Be careful with changing it too much, because it causes your estimated human position to be slower to sudden changes - if you stop, filter won’t trust as much your readings and as a result it will predict you will still move with some velocity. Consequently robot will continue moving forward and it will take some time to adjust to reality. On the other hand if you decrease it too much human position will fluctuate with uncertainties in leg detections.</li>
</ul>

<p>Next big change is that I added scoring system which uses all parameters: proportion, area, length and distance. It combines it with appropriate weights.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">proportion</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">xDistance</span><span class="p">,</span><span class="n">yDistance</span><span class="p">)</span><span class="o">/</span><span class="nb">min</span><span class="p">(</span><span class="n">xDistance</span><span class="p">,</span> <span class="n">yDistance</span><span class="p">)</span>
<span class="n">area</span> <span class="o">=</span> <span class="n">xDistance</span><span class="o">*</span><span class="n">yDistance</span>
<span class="n">widthDifference</span> <span class="o">=</span> <span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">xDistance</span><span class="p">,</span><span class="n">yDistance</span><span class="p">)</span><span class="o">-</span><span class="bp">self</span><span class="p">.</span><span class="n">legWidth</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">dLegWidth</span>
<span class="n">distanceFromRobot</span> <span class="o">=</span> <span class="n">math</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">xMean</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">yMean</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="n">score</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">score</span> <span class="o">+=</span> <span class="n">distanceFromRobot</span> <span class="o">*</span> <span class="bp">self</span><span class="p">.</span><span class="n">distanceWeight</span>
<span class="n">score</span> <span class="o">+=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">proportion</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">destProportion</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="p">.</span><span class="n">proportionWeight</span>
<span class="n">score</span> <span class="o">+=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">area</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">destArea</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="p">.</span><span class="n">areaWeight</span>
<span class="k">if</span> <span class="n">widthDifference</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">score</span> <span class="o">+=</span> <span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">widthDifference</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="p">.</span><span class="n">widthDifferenceWeight</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
<span class="k">if</span> <span class="n">score</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="p">.</span><span class="n">maxScore</span><span class="p">:</span>
    <span class="n">sortedClustersDetails</span><span class="p">.</span><span class="n">append</span><span class="p">([</span><span class="n">xMean</span><span class="p">,</span> <span class="n">yMean</span><span class="p">,</span> <span class="n">distanceFromRobot</span><span class="p">,</span> <span class="n">proportion</span><span class="p">,</span> <span class="n">area</span><span class="p">,</span> <span class="n">widthDifference</span><span class="p">,</span> <span class="n">score</span><span class="p">])</span>
</code></pre></div></div>

<p>Parameters:</p>

<ul>
  <li><strong>destProportion</strong> - our desired proportion, I set it based on readings I got</li>
  <li><strong>destArea</strong> - same as above but with area</li>
  <li><strong>distanceWeight</strong> - weight we give to distance from robot</li>
  <li><strong>proportionWeight</strong> - weight we set to distance between measured proportion and desired</li>
  <li><strong>areaWeight</strong> - don’t set this weight too high, as it is not as reliable</li>
  <li><strong>widthDifferenceWeight</strong> - we set it really high, because when reading is too long, then it’s probably not a leg</li>
  <li><strong>maxScore</strong> - above that score we are certain that detection isn’t a leg</li>
</ul>

<p>Parameters with updated values:</p>

<ul>
  <li><strong>minRange</strong> (increased) - robot has to detect obstacles earlier</li>
  <li><strong>speedPGain</strong> (increased) - increase in proportional gain to obtain higher speed</li>
  <li><strong>angularSpeedPGain</strong> (increased) - same as above</li>
  <li><strong>minHumanDistance</strong> (decreased) - robot will start following earlier and be able to keep up with human</li>
  <li><strong>humanPositionChangeThreshold</strong> (increased) - person walks faster so position can change more</li>
  <li><strong>detectionTimeout</strong> (decreased) - higher speeds, so we decrease timeouts</li>
  <li><strong>buttonTimeout</strong> (decreased) - same as above</li>
</ul>

<p>Lastly I added restrictions on obstacle detect - we only detect obstacle approximately in area where we can drive. Increasing minRange can cause ROSbot to be unable to move in narrow spaces.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">if</span> <span class="p">(</span><span class="n">alfa</span> <span class="o">&gt;</span> <span class="o">-</span><span class="n">math</span><span class="p">.</span><span class="n">pi</span> <span class="ow">and</span> <span class="n">alfa</span> <span class="o">&lt;</span> <span class="o">-</span><span class="bp">self</span><span class="p">.</span><span class="n">maxAngle</span><span class="p">)</span> <span class="ow">or</span> \
	<span class="p">(</span><span class="n">alfa</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="p">.</span><span class="n">maxAngle</span> <span class="ow">and</span> <span class="n">alfa</span> <span class="o">&lt;</span> <span class="n">math</span><span class="p">.</span><span class="n">pi</span><span class="p">):</span>
</code></pre></div></div>

<h2 id="summary">Summary</h2>

<p>In this tutorial you learned how to set up and run human following using ROSbot with ESP remote. After main algorithm walkthrough you should be also able to modify it to suit your robot.</p>]]></content><author><name></name></author><category term="Robots" /><summary type="html"><![CDATA[Every move you make | Every step you take | I'll follow you]]></summary></entry><entry><title type="html">Tank</title><link href="http://localhost:4000/robots/2019/03/27/tank/" rel="alternate" type="text/html" title="Tank" /><published>2019-03-27T00:00:00+01:00</published><updated>2019-03-27T00:00:00+01:00</updated><id>http://localhost:4000/robots/2019/03/27/tank</id><content type="html" xml:base="http://localhost:4000/robots/2019/03/27/tank/"><![CDATA[<p>General-purpose mobile robot based on Raspberry Pi Zero.</p>

<figure class="figure  figure--center">
  <img class="image" src="/pics/Czolg/front.jpg" alt="" width="600" height="800" />
  
</figure>

<p>The robot can be teleoperated using a web browser, it works quite well in rough terrain:</p>

<div class="embed-container">
  <iframe width="720" height="405" src="https://drive.google.com/file/d/1QSsrb819J34oQ7zTbSGpt-7YVE9Y9KgX/preview" frameborder="0" allowfullscreen="">
  </iframe>
</div>

<p>Construction started with PCB:</p>
<figure class="figure  figure--center">
  <img class="image" src="/pics/Czolg/pierwotna.jpg" alt="PCB with connected components" width="600" height="800" />
  <figcaption class="caption">PCB with connected components</figcaption>
</figure>

<p>The PCB was supposed to control the following components:</p>
<ul>
  <li>2 motors with encoders</li>
  <li>3 servos</li>
  <li>SPI communication with Raspberry</li>
  <li>battery voltage measurements</li>
  <li>2 LEDs (indicating low battery voltage and “power on”)</li>
</ul>

<figure class="figure  figure--center">
  <img class="image" src="/pics/Czolg/testowanie.jpg" alt="Prototyping PCB" width="600" height="800" />
  <figcaption class="caption">Prototyping PCB</figcaption>
</figure>

<p>As a power source I used a LiPol battery that was connected to 2 voltage converters: one for the microcontroller and one for servos.</p>

<figure class="figure  figure--center">
  <img class="image" src="/pics/Czolg/plytkawobudowie.jpg" alt="" width="600" height="800" />
  
</figure>

<p>Parts of the construction were 3D printed using 
<a href="https://www.thingiverse.com/thing:652851" title="Construction">https://www.thingiverse.com/thing:652851</a></p>

<figure class="figure  figure--center">
  <img class="image" src="/pics/Czolg/plytka.jpg" alt="PCB" width="600" height="800" />
  <figcaption class="caption">PCB</figcaption>
</figure>

<p>The robot was controlled through a web browser, I used <a href="https://hackaday.io/project/25092-zerobot-raspberry-pi-zero-fpv-robot/log/97988-the-new-zerobot-pro" title="Code">https://hackaday.io/project/25092-zerobot-raspberry-pi-zero-fpv-robot/log/97988-the-new-zerobot-pro</a>, modified to work with my SPI communication.</p>

<p><a class="button" href="https://github.com/macstepien/Tank" style="background: #0366d6">Tank  <svg width="16" height="16" class="icon  icon--github" role="img" alt="github"><title>github</title><use xlink:href="#github" fill="CurrentColor"></use></svg>
</a></p>]]></content><author><name></name></author><category term="Robots" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Hexapod</title><link href="http://localhost:4000/robots/2018/06/08/hexapod/" rel="alternate" type="text/html" title="Hexapod" /><published>2018-06-08T00:00:00+02:00</published><updated>2018-06-08T00:00:00+02:00</updated><id>http://localhost:4000/robots/2018/06/08/hexapod</id><content type="html" xml:base="http://localhost:4000/robots/2018/06/08/hexapod/"><![CDATA[<p>I worked on this project during my first two years of university in the Integra student research group. My contribution was software (both for controlling the robot and stereo vision).</p>

<figure class="figure  figure--center">
  <img class="image" src="/pics/Hexapod/hexi.jpg" alt="" width="600" height="800" />
  
</figure>

<p>In the robot construction 18 Hitec servos (3 for each leg) were used. Raspberry Pi 2 was the main brain of the robot, it controlled servos through the Pololu driver (using UART communication). 4000mAh LiPol battery allowed for around 1h work time, voltage converters were necessary (3 for servos and 1 for Raspberry). MCP3008 ADC was used to measure battery voltage, it sent current value using SPI to the Raspberry, which was later sent and displayed in the client application.</p>

<div class="embed-container">
  <iframe width="720" height="405" src="https://drive.google.com/file/d/1kR9fSGo-6mLM5SdvNPUtoAvgJeeI8Lu-/preview" frameborder="0" allowfullscreen="">
  </iframe>
</div>

<p>The robot can be controlled using a gamepad or keyboard connected to the laptop, which sends commands to the Raspberry using TCP and WiFi. Using a mathematical model of the robot, the control application calculates the position of the tip of the leg to achieve the desired movement. Then it is converted to joint angles using inverse kinematics, which are used to calculate PWM signals sent to servos.</p>

<figure class="figure  figure--center">
  <img class="image" src="/pics/Hexapod/symulacja.png" alt="" width="600" height="800" />
  
</figure>

<h2 id="robot-control">Robot control</h2>

<p>Application run on laptop includes robot model and sents user commands over to Raspberry Pi mounted on the robot. They are then converted into PWM signals used for servo control. The current battery voltage is sent back from Raspberry to the client application.</p>

<p>A separate application is used for stereo vision. Using GStreamer image streams from both cameras are sent from Raspberry to the main application run on a laptop. Then they are processed and disparity image is calculated, which is later used to get information about the distance to obstacles nearby.</p>

<p>The client application can work in 2 modes:</p>

<h4 id="simulation-mode">Simulation mode</h4>

<p>In simulation mode camera can be controlled using keys  W/S/A/D/Q/E and alfa, beta and gamma bars (for changing camera angles). The robot can be controlled using w/s/a/d/q/e and numerical keys to choose a walking mode.</p>

<div class="embed-container">
  <iframe width="720" height="405" src="https://drive.google.com/file/d/1ixW05vog_nNaR9UR6ZqT5rZBkIWlBJeN/preview" frameborder="0" allowfullscreen="">
  </iframe>
</div>

<h4 id="hexapod-connection-mode">Hexapod connection mode</h4>

<p>When the Raspberry Pi address is passed to the client application, it additionally connects to it and sends commands to the robot.</p>

<p>A more detailed description of implementation:</p>

<h4 id="gui">GUI</h4>

<p>The GUI of the application was realized using OpenCV, the camera was simulated using 3D projection <a href="https://en.wikipedia.org/wiki/3D_projection" title="1">1</a>. The whole simulated world was projected onto a camera plane, which can be moved around the environment.</p>

<h4 id="robot">Robot</h4>

<p>This main module is responsible for all calculations necessary for controlling the robot. It includes inverse kinematics implementation (using <a href="https://oscarliang.com/inverse-kinematics-and-trigonometry-basics/" title="2">2</a>).</p>

<h4 id="walking">Walking</h4>

<p>It generates trajectory points for the tip of the leg to get to the desired position (various approaches were tested, and the best results were achieved with parabolic trajectory). Then using inverse kinematics they are translated into joint commands.</p>

<h4 id="other-modules">Other modules</h4>

<p>It was also necessary to implement conversion between desired joint angle and the PWM signal (it required calibrating servos).</p>

<h4 id="tcp">TCP</h4>

<p>The TCP module is responsible for communication between Raspberry and the client application. It was based on <a href="https://github.com/vichargrave/tcpsockets" title="3">3</a>. Battery voltage is read on the Raspberry (in a separate thread) and sent on port 8081, which is later read by the client application and shown on the screen. On port 8080 client application sends control commands to the Raspberry.</p>

<p><a class="button" href="https://github.com/macstepien/HexapodPC" style="background: #0366d6">Client application  <svg width="16" height="16" class="icon  icon--github" role="img" alt="github"><title>github</title><use xlink:href="#github" fill="CurrentColor"></use></svg>
</a></p>

<p><a class="button" href="https://github.com/macstepien/HexapodRaspberry" style="background: #0366d6">Raspberry application  <svg width="16" height="16" class="icon  icon--github" role="img" alt="github"><title>github</title><use xlink:href="#github" fill="CurrentColor"></use></svg>
</a></p>

<h2 id="stereo-vision">Stereo vision</h2>

<h3 id="calibration-images">Calibration images</h3>

<p>To calibrate pair of stereo vision cameras it is necessary to take several pictures of some pattern, in this case it was a chessboard. For this purpose I saved around 50 images with chessboard pattern in different positions and orientations.</p>

<figure class="figure  figure--center">
  <img class="image" src="/pics/Hexapod/stereo12.png" alt="One of calibration image pairs" width="600" height="800" />
  <figcaption class="caption">One of calibration image pairs</figcaption>
</figure>

<p>There was one problem with the cameras’ mounting - they weren’t properly aligned. This shift was fixed during calibration, but as a result, the stereo vision field of view is slightly decreased.</p>

<h3 id="calibration">Calibration</h3>

<p>Calibration was based on the example from the book “Learning OpenCV”. As input it required the number of rows and columns of the chessboard and the length of one square side (it was important to print the chessboard in original proportions so that squares won’t become rectangles, which will break the calibration process).</p>

<figure class="figure  figure--center">
  <img class="image" src="/pics/Hexapod/stereo3.png" alt="Result of chessboard detection" width="400" height="800" />
  <figcaption class="caption">Result of chessboard detection</figcaption>
</figure>

<figure class="figure  figure--center">
  <img class="image" src="/pics/Hexapod/stereo4.png" alt="Rectification" width="700" height="800" />
  <figcaption class="caption">Rectification</figcaption>
</figure>

<p>The result of the calibration was intrinsic and extrinsic camera parameters, errors of this process were:
Mean square error (RMS) = 0.0503053
Epipolar mean error = 0.517146
These error values are quite low, which means that calibration was successful.</p>

<h3 id="algorithm-and-parameters">Algorithm and parameters</h3>

<p>I tested SGBM and BM algorithms from the OpenCV library, better results were achieved for SGBM. CPU usage was higher for this algorithm, but still it was possible to get real-time results for images with 320x240 resolution. Then I tuned the parameters of the SGBM algorithm, using the application that allowed dynamic reconfiguration of parameters using sliders.</p>

<figure class="figure  figure--center">
  <img class="image" src="/pics/Hexapod/stereo5.png" alt="Parameter tunning application with sliders" width="400" height="800" />
  <figcaption class="caption">Parameter tunning application with sliders</figcaption>
</figure>

<figure class="figure  figure--center">
  <img class="image" src="/pics/Hexapod/stereo6.png" alt="Scene used for parameter tunning" width="400" height="800" />
  <figcaption class="caption">Scene used for parameter tunning</figcaption>
</figure>

<figure class="figure  figure--center">
  <img class="image" src="/pics/Hexapod/stereo7.png" alt="Result of stereo vision" width="400" height="800" />
  <figcaption class="caption">Result of stereo vision</figcaption>
</figure>

<h3 id="postfiltration-parameters">Postfiltration parameters</h3>

<p>To get a smoother result I additionally used postfiltration from contrib OpenCV modules.</p>

<figure class="figure  figure--center">
  <img class="image" src="/pics/Hexapod/stereo9.png" alt="Raw disparity image" width="400" height="800" />
  <figcaption class="caption">Raw disparity image</figcaption>
</figure>

<figure class="figure  figure--center">
  <img class="image" src="/pics/Hexapod/stereo10.png" alt="Disparity image after postfiltration" width="400" height="800" />
  <figcaption class="caption">Disparity image after postfiltration</figcaption>
</figure>

<h3 id="application">Application</h3>

<p>The final application combined all the elements described above - video stream from cameras connected to Raspberry was sent to the laptop, then images were rectified, pixels matched using SGBM, disparity image calculated and then filtered. Finally disparity was displayed on the screen, as the next step it should be used to calculate the point cloud, which then could be used for obstacle detection.</p>

<p>Getting satisfactory video transmission wasn’t that easy. In the first approach MJPGstreamer was used, but the results weren’t too good - all frames were buffered and as it wasn’t possible to send them in real-time, the delay between registering the image and analyzing it using stereo vision was increasing. Additionally images from two cameras weren’t synchronized. So instead I used GStreamer, which was more tricky to set up, but the results were much better. The resolution of sent images was 320x240 (for 640x480 FPS was too low).</p>

<p><a class="button" href="https://github.com/macstepien/HexapodStereovision" style="background: #0366d6">Stereo vision  <svg width="16" height="16" class="icon  icon--github" role="img" alt="github"><title>github</title><use xlink:href="#github" fill="CurrentColor"></use></svg>
</a></p>

<h3 id="achievements">Achievements</h3>

<h4 id="robotic-competitions">Robotic competitions</h4>

<ul>
  <li>Robocomp 2017 in Cracow (Freestyle category)</li>
  <li>Robotic Arena 2017 in Wrocław (Freestyle and Robosprint). 1st place in Robosprint.</li>
  <li>Robomaticon 2018 in Warsaw (Freestyle)</li>
  <li>Robotic Tournament 2018 in Rybnik (Freestyle)</li>
  <li>Robotic Arena 2019 in Wrocław. 2nd place in Robosprint.</li>
  <li>Robocomp 2019 in Cracow. 3rd place in Robosprint</li>
  <li>Robotic Arena 2020 in Wrocław. 3rd place in Robosprint.</li>
</ul>

<h4 id="events">Events</h4>

<ul>
  <li>Targi pracy Kariera IT</li>
  <li>TEDxAGHUniversity</li>
</ul>

<figure class="figure  figure--center">
  <img class="image" src="/pics/Hexapod/robotic_arena.jpg" alt="Hexapod on Robotic Arena 2017, photo by Wrocław UST" width="400" height="800" />
  <figcaption class="caption">Hexapod on Robotic Arena 2017, photo by Wrocław UST</figcaption>
</figure>

<p><a href="http://www.integra.agh.edu.pl/robot-kroczacy-freestyle/" title="Project page">Project page</a></p>]]></content><author><name></name></author><category term="Robots" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Luminous ball</title><link href="http://localhost:4000/software/2017/05/26/move/" rel="alternate" type="text/html" title="Luminous ball" /><published>2017-05-26T00:00:00+02:00</published><updated>2017-05-26T00:00:00+02:00</updated><id>http://localhost:4000/software/2017/05/26/move</id><content type="html" xml:base="http://localhost:4000/software/2017/05/26/move/"><![CDATA[<p>Motion controller for PC.</p>

<figure class="figure  figure--center">
  <img class="image" src="/pics/swiecacaKulka/kontroler.jpg" alt="" width="300" height="300" />
  
</figure>

<p>The controller was inspired by the PlayStation Move and consists of a flashlight with a ball. The ball’s movements are tracked on a webcam and translated into mouse cursor movements. By turning the flashlight on and off a mouse click is simulated.</p>

<p>To analyze the image and detect the ball I used the OpenCV library and the detection method as in the <a href="https://forbot.pl/blog/opencv-2-wykrywanie-obiektow-id4888">https://forbot.pl/blog/opencv-2-wykrywanie-obiektow-id4888</a></p>

<div class="embed-container">
  <iframe width="720" height="405" src="https://drive.google.com/file/d/1Ifl4nigfpzm73YRJDlyJJY3RQRywG9NQ/preview" frameborder="0" allowfullscreen="">
  </iframe>
</div>

<p><a class="button" href="https://github.com/macstepien/LightOrb" style="background: #0366d6">Code  <svg width="16" height="16" class="icon  icon--github" role="img" alt="github"><title>github</title><use xlink:href="#github" fill="CurrentColor"></use></svg>
</a></p>]]></content><author><name></name></author><category term="Software" /><summary type="html"><![CDATA[Motion controller for PC]]></summary></entry><entry><title type="html">Fuzz guitar effect</title><link href="http://localhost:4000/electronics/2016/08/28/fuzz/" rel="alternate" type="text/html" title="Fuzz guitar effect" /><published>2016-08-28T00:00:00+02:00</published><updated>2016-08-28T00:00:00+02:00</updated><id>http://localhost:4000/electronics/2016/08/28/fuzz</id><content type="html" xml:base="http://localhost:4000/electronics/2016/08/28/fuzz/"><![CDATA[<figure class="figure  figure--center">
  <img class="image" src="/pics/fuzz/front.jpg" alt="" width="600" height="" />
  
</figure>

<p>Guitar effect made using the schematic:</p>
<figure class="figure  figure--center">
  <img class="image" src="/pics/fuzz/fuzzSchemat.gif" alt="" width="600" height="800" />
  
</figure>

<figure class="figure  figure--center">
  <img class="image" src="/pics/fuzz/inside.jpg" alt="" width="600" height="" />
  
</figure>]]></content><author><name></name></author><category term="Electronics" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Tesla coil</title><link href="http://localhost:4000/electronics/2015/12/10/cewkatesli/" rel="alternate" type="text/html" title="Tesla coil" /><published>2015-12-10T00:00:00+01:00</published><updated>2015-12-10T00:00:00+01:00</updated><id>http://localhost:4000/electronics/2015/12/10/cewkatesli</id><content type="html" xml:base="http://localhost:4000/electronics/2015/12/10/cewkatesli/"><![CDATA[<figure class="figure  figure--center">
  <img class="image" src="/pics/cewkatesli/wieksza.jpg" alt="" width="600" height="800" />
  
</figure>

<p>Inspired by
<a href="https://www.electroboom.com/?p=521" title="ElectroBoom">ElectroBoom</a>
and
<a href="https://www.youtube.com/watch?v=4OC7cwI4RNM" title="Ludic Science">Ludic Science</a></p>

<figure class="figure  figure--center">
  <img class="image" src="/pics/cewkatesli/oryginal.jpg" alt="" width="400" height="800" />
  
</figure>

<p>First I made a smaller version based on a single transistor, powered by a 9V battery.</p>

<figure class="figure  figure--center">
  <img class="image" src="/pics/cewkatesli/nawijanie.jpg" alt="Coil winding" width="600" height="800" />
  <figcaption class="caption">Coil winding</figcaption>
</figure>

<p>Then I made a larger coil, in which I used 4 transistors and an additional heat sink to ensure adequate cooling. I used a power supply from a printer as a power source.</p>]]></content><author><name></name></author><category term="Electronics" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Mapping robot</title><link href="http://localhost:4000/robots/2015/08/25/mapping-robot/" rel="alternate" type="text/html" title="Mapping robot" /><published>2015-08-25T00:00:00+02:00</published><updated>2015-08-25T00:00:00+02:00</updated><id>http://localhost:4000/robots/2015/08/25/mapping-robot</id><content type="html" xml:base="http://localhost:4000/robots/2015/08/25/mapping-robot/"><![CDATA[<p>Robot that drives around and creates a map of the environment.</p>

<figure class="figure  figure--center">
  <img class="image" src="/pics/RobotMapujacy/front.jpg" alt="" width="600" height="800" />
  
</figure>

<p>This robot was a simplified version of a previously created general-purpose robot. In this construction I simplified requirements and focused only on mapping and navigation. Instead of stereo vision I decided to use a Kinect sensor because results achieved previously with only cameras weren’t satisfactory. I also added custom-made wheel encoders based on optocouplers and black and white patterns on wheels.</p>

<figure class="figure  figure--center">
  <img class="image" src="/pics/RobotMapujacy/test.jpg" alt="Prototype of electronic components connections" width="600" height="800" />
  <figcaption class="caption">Prototype of electronic components connections</figcaption>
</figure>

<p>On this robot I implemented a PID controller for driving up to the point:</p>

<p><a class="button" href="https://github.com/macstepien/MappingRobotPID" style="background: #0366d6">PID  <svg width="16" height="16" class="icon  icon--github" role="img" alt="github"><title>github</title><use xlink:href="#github" fill="CurrentColor"></use></svg>
</a></p>

<div class="embed-container">
  <iframe width="720" height="405" src="https://drive.google.com/file/d/1SI5PMQt-zXZ0vf6xvoXPK_p1-t72E7ty/preview" frameborder="0" allowfullscreen="">
  </iframe>
</div>

<p>To create a map of the environment first it was necessary to remove floor points from data from Kinect. I tested two approaches - fitting the plane using the RANSAC algorithm and the UV-disparity method (which required lower computational load - instead of plane line was fitted).</p>

<figure class="figure  figure--center">
  <img class="image" src="/pics/RobotMapujacy/side.jpg" alt="" width="600" height="800" />
  
</figure>

<p>Then obstacle points were projected onto grid map, robot position was calculated using wheel encoders.</p>
<figure class="figure  figure--center">
  <img class="image" src="/pics/RobotMapujacy/map.jpg" alt="" width="500" height="800" />
  
</figure>

<p><a class="button" href="https://github.com/macstepien/MappingRobotKinect" style="background: #0366d6">Kinect mapping  <svg width="16" height="16" class="icon  icon--github" role="img" alt="github"><title>github</title><use xlink:href="#github" fill="CurrentColor"></use></svg>
</a></p>

<div class="embed-container">
  <iframe width="720" height="405" src="https://drive.google.com/file/d/11cBjTDrB67s6sojRpdoVRc-anlgDSwj5/preview" frameborder="0" allowfullscreen="">
  </iframe>
</div>

<p><a class="button" href="https://github.com/macstepien/MappingRobotStereovision" style="background: #0366d6">Stereo vision mapping  <svg width="16" height="16" class="icon  icon--github" role="img" alt="github"><title>github</title><use xlink:href="#github" fill="CurrentColor"></use></svg>
</a></p>

<p>I also tried to run a SLAM algorithm to correct errors from encoders but wasn’t able to run any available implementation on Windows (which I was using at that time).</p>

<figure class="figure  figure--center">
  <img class="image" src="/pics/RobotMapujacy/pcb.jpg" alt="" width="600" height="800" />
  
</figure>

<p>To control the robot I used an Atmega88Pa microcontroller, which was connected using a USB-UART converter to the computer. It controlled motors (continuous rotation servos) and measured optocouplers voltage to detect wheel rotations. Additionally, I used an infrared proximity sensor. As a power source, I used a 6V gel battery, voltage on battery was measured and monitored by MCU. A 12V Step-Up voltage converter was used to power Kinect.</p>

<p><a class="button" href="https://github.com/macstepien/MappingRobotControler" style="background: #0366d6">Mapping robot controller  <svg width="16" height="16" class="icon  icon--github" role="img" alt="github"><title>github</title><use xlink:href="#github" fill="CurrentColor"></use></svg>
</a></p>]]></content><author><name></name></author><category term="Robots" /><summary type="html"><![CDATA[Robot that drives around and creates a map of the environment.]]></summary></entry><entry><title type="html">3D Viewer</title><link href="http://localhost:4000/software/2015/04/09/3dviewer/" rel="alternate" type="text/html" title="3D Viewer" /><published>2015-04-09T00:00:00+02:00</published><updated>2015-04-09T00:00:00+02:00</updated><id>http://localhost:4000/software/2015/04/09/3dviewer</id><content type="html" xml:base="http://localhost:4000/software/2015/04/09/3dviewer/"><![CDATA[<p>Application for the perspective visualization of point clouds in 3D.</p>

<figure class="figure  figure--center">
  <img class="image" src="/pics/3dviewer/viewer1.png" alt="" width="600" height="800" />
  
</figure>

<p>Point clouds (positions (X, Y, Z), color (R, G, B)) is read from a txt file and then projected on the camera plane in a simulated environment. The camera can be moved around. Point clouds that I visualized were calculated using the stereo vision camera that I constructed. Additionally, it is possible to display simple geometric shapes.</p>

<figure class="figure  figure--center">
  <img class="image" src="/pics/3dviewer/viewer2.png" alt="" width="600" height="800" />
  
</figure>

<p><a class="button" href="https://github.com/macstepien/3DViewer" style="background: #0366d6">3DViewer  <svg width="16" height="16" class="icon  icon--github" role="img" alt="github"><title>github</title><use xlink:href="#github" fill="CurrentColor"></use></svg>
</a></p>]]></content><author><name></name></author><category term="Software" /><summary type="html"><![CDATA[Application for the perspective visualization of point clouds in 3D.]]></summary></entry><entry><title type="html">General-purpose robot</title><link href="http://localhost:4000/robots/2014/08/28/universal-robots/" rel="alternate" type="text/html" title="General-purpose robot" /><published>2014-08-28T00:00:00+02:00</published><updated>2014-08-28T00:00:00+02:00</updated><id>http://localhost:4000/robots/2014/08/28/universal-robots</id><content type="html" xml:base="http://localhost:4000/robots/2014/08/28/universal-robots/"><![CDATA[<p>It was my first attempt at creating a general-purpose robot. Due to the low budget, it was supposed to be only a scaled version, without many real capabilities, only a proof-of-concept.</p>

<figure class="figure  figure--center">
  <img class="image" src="/pics/RobotUniwersalny/robot.jpg" alt="" width="300" height="800" />
  
</figure>

<p>In this construction, I planned to use 11 servos, which were more than the available PWM lines on Atmega88Pa microcontroller that I used. That’s why I was generating a PWM signal using a timer, but due to high resource usage, it was necessary to dedicate one microcontroller solely for this purpose. The second microcontroller was used to communicate with a computer, control wheel motors and send commands to the first MCU using SPI. This approach was very complicated and because of additional problems with the power supply, I decided to skip manipulation and focus on navigation. As the only sensor in this task, I used stereo vision. I was able to make it work quite well statically, but when mounted on the robot, motion caused images from cameras to become blurry and as a result detected point cloud wasn’t accurate enough.</p>

<figure class="figure  figure--center">
  <img class="image" src="/pics/RobotUniwersalny/plytka.jpg" alt="" width="600" height="800" />
  
</figure>

<figure class="figure  figure--center">
  <img class="image" src="/pics/RobotUniwersalny/parts.jpg" alt="" width="600" height="800" />
  
</figure>]]></content><author><name></name></author><category term="Robots" /><summary type="html"><![CDATA[]]></summary></entry></feed>